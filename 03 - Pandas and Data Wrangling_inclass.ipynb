{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on: `pandas` & Data Cleaning\n",
    "\n",
    "This hands-on will cover handling data using the `pandas` library.\n",
    "- Reading in data\n",
    "- Descriptive statistics\n",
    "- Data wrangling\n",
    "- Filtering\n",
    "- Aggregation\n",
    "- Merging\n",
    "\n",
    "_This notebook was derived from the Introduction to Data Science notebooks by Unisse Chua, Jude Teves and Sashmir Yap of the Data Science Institute._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports are placed at the top of the notebook \n",
    "# to ensure that any library needed to fully run the notebook are loaded (and installed)\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility\n",
    "\n",
    "With data science, or any project that requires data processing and analysis, it is important to ensure that the code provided can be replicated by other members of the team. One such way is by setting up an **environment variable** that represents a central location for the data files.\n",
    "\n",
    "Steps: \n",
    "1. Create a folder in your computer to serve as the location for all the data files of your project.\n",
    "2. Save the directory path as an environment variable. The name of the variable should be the same for all team members so that everyone would simply have to use this name across their code.\n",
    "\n",
    "This folder will host **only DATA files**. Code may be kept elsewhere. The code simply needs to reference to this folder when accessing and saving data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Unisse/Documents/Projects/dlsu/DATAPRE/datapre-notebooks/data')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSDATA = Path(os.getenv('DSDATA'))\n",
    "DSDATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The Philippines has an Open Data portal: https://data.gov.ph\n",
    "\n",
    "For this exercise, we'll be using the [Public Elementary School Enrollment Statistics](https://data.gov.ph/?q=dataset/public-elementary-school-enrollment-statistics) provided by the Department of Education. The page contains two files. Download both files and save them to the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "\"`pandas` is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\" - [Source](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "\n",
    "Commonly used file types for published *(semi-)* structured data are **CSV (or TSV)** and sometimes even **Excel** (although this is not an 'open' format). In `pandas`, it's straightforward to read in these types of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PathLike[str]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIO\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRawIOBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextIOBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextIOWrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmap\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mobject\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[1;36m0x000001F5210B8F40\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmangle_dupe_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskip_blank_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep_date_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcache_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0miterator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwarn_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfloat_precision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Read a comma-separated values (csv) file into DataFrame.\n",
       "\n",
       "Also supports optionally iterating or breaking of the file\n",
       "into chunks.\n",
       "\n",
       "Additional help can be found in the online docs for\n",
       "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filepath_or_buffer : str, path object or file-like object\n",
       "    Any valid string path is acceptable. The string could be a URL. Valid\n",
       "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
       "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
       "\n",
       "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
       "\n",
       "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
       "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
       "sep : str, default ','\n",
       "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
       "    the separator, but the Python parsing engine can, meaning the latter will\n",
       "    be used and automatically detect the separator by Python's builtin sniffer\n",
       "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
       "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
       "    will also force the use of the Python parsing engine. Note that regex\n",
       "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
       "delimiter : str, default ``None``\n",
       "    Alias for sep.\n",
       "header : int, list of int, default 'infer'\n",
       "    Row number(s) to use as the column names, and the start of the\n",
       "    data.  Default behavior is to infer the column names: if no names\n",
       "    are passed the behavior is identical to ``header=0`` and column\n",
       "    names are inferred from the first line of the file, if column\n",
       "    names are passed explicitly then the behavior is identical to\n",
       "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
       "    replace existing names. The header can be a list of integers that\n",
       "    specify row locations for a multi-index on the columns\n",
       "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
       "    skipped (e.g. 2 in this example is skipped). Note that this\n",
       "    parameter ignores commented lines and empty lines if\n",
       "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
       "    data rather than the first line of the file.\n",
       "names : array-like, optional\n",
       "    List of column names to use. If the file contains a header row,\n",
       "    then you should explicitly pass ``header=0`` to override the column names.\n",
       "    Duplicates in this list are not allowed.\n",
       "index_col : int, str, sequence of int / str, or False, default ``None``\n",
       "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
       "  string name or column index. If a sequence of int / str is given, a\n",
       "  MultiIndex is used.\n",
       "\n",
       "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
       "  column as the index, e.g. when you have a malformed file with delimiters at\n",
       "  the end of each line.\n",
       "usecols : list-like or callable, optional\n",
       "    Return a subset of the columns. If list-like, all elements must either\n",
       "    be positional (i.e. integer indices into the document columns) or strings\n",
       "    that correspond to column names provided either by the user in `names` or\n",
       "    inferred from the document header row(s). For example, a valid list-like\n",
       "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
       "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
       "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
       "    in ``['foo', 'bar']`` order or\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
       "    for ``['bar', 'foo']`` order.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the column\n",
       "    names, returning names where the callable function evaluates to True. An\n",
       "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
       "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
       "    parsing time and lower memory usage.\n",
       "squeeze : bool, default False\n",
       "    If the parsed data only contains one column then return a Series.\n",
       "prefix : str, optional\n",
       "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
       "mangle_dupe_cols : bool, default True\n",
       "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
       "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
       "    are duplicate names in the columns.\n",
       "dtype : Type name or dict of column -> type, optional\n",
       "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
       "    'c': 'Int64'}\n",
       "    Use `str` or `object` together with suitable `na_values` settings\n",
       "    to preserve and not interpret dtype.\n",
       "    If converters are specified, they will be applied INSTEAD\n",
       "    of dtype conversion.\n",
       "engine : {'c', 'python'}, optional\n",
       "    Parser engine to use. The C engine is faster while the python engine is\n",
       "    currently more feature-complete.\n",
       "converters : dict, optional\n",
       "    Dict of functions for converting values in certain columns. Keys can either\n",
       "    be integers or column labels.\n",
       "true_values : list, optional\n",
       "    Values to consider as True.\n",
       "false_values : list, optional\n",
       "    Values to consider as False.\n",
       "skipinitialspace : bool, default False\n",
       "    Skip spaces after delimiter.\n",
       "skiprows : list-like, int or callable, optional\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
       "    at the start of the file.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the row\n",
       "    indices, returning True if the row should be skipped and False otherwise.\n",
       "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
       "skipfooter : int, default 0\n",
       "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
       "nrows : int, optional\n",
       "    Number of rows of file to read. Useful for reading pieces of large files.\n",
       "na_values : scalar, str, list-like, or dict, optional\n",
       "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
       "    per-column NA values.  By default the following values are interpreted as\n",
       "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
       "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
       "    'nan', 'null'.\n",
       "keep_default_na : bool, default True\n",
       "    Whether or not to include the default NaN values when parsing the data.\n",
       "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
       "\n",
       "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
       "      is appended to the default NaN values used for parsing.\n",
       "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
       "      the default NaN values are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
       "      the NaN values specified `na_values` are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
       "      strings will be parsed as NaN.\n",
       "\n",
       "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
       "    `na_values` parameters will be ignored.\n",
       "na_filter : bool, default True\n",
       "    Detect missing value markers (empty strings and the value of na_values). In\n",
       "    data without any NAs, passing na_filter=False can improve the performance\n",
       "    of reading a large file.\n",
       "verbose : bool, default False\n",
       "    Indicate number of NA values placed in non-numeric columns.\n",
       "skip_blank_lines : bool, default True\n",
       "    If True, skip over blank lines rather than interpreting as NaN values.\n",
       "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
       "    The behavior is as follows:\n",
       "\n",
       "    * boolean. If True -> try parsing the index.\n",
       "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
       "      a single date column.\n",
       "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
       "      result 'foo'\n",
       "\n",
       "    If a column or index cannot be represented as an array of datetimes,\n",
       "    say because of an unparsable value or a mixture of timezones, the column\n",
       "    or index will be returned unaltered as an object data type. For\n",
       "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
       "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
       "    specify ``date_parser`` to be a partially-applied\n",
       "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
       "    :ref:`io.csv.mixed_timezones` for more.\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "infer_datetime_format : bool, default False\n",
       "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
       "    format of the datetime strings in the columns, and if it can be inferred,\n",
       "    switch to a faster method of parsing them. In some cases this can increase\n",
       "    the parsing speed by 5-10x.\n",
       "keep_date_col : bool, default False\n",
       "    If True and `parse_dates` specifies combining multiple columns then\n",
       "    keep the original columns.\n",
       "date_parser : function, optional\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by `parse_dates` into a single array\n",
       "    and pass that; and 3) call `date_parser` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
       "    arguments.\n",
       "dayfirst : bool, default False\n",
       "    DD/MM format dates, international and European format.\n",
       "cache_dates : bool, default True\n",
       "    If True, use a cache of unique, converted dates to apply the datetime\n",
       "    conversion. May produce significant speed-up when parsing duplicate\n",
       "    date strings, especially ones with timezone offsets.\n",
       "\n",
       "    .. versionadded:: 0.25.0\n",
       "iterator : bool, default False\n",
       "    Return TextFileReader object for iteration or getting chunks with\n",
       "    ``get_chunk()``.\n",
       "\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "       ``TextFileReader`` is a context manager.\n",
       "chunksize : int, optional\n",
       "    Return TextFileReader object for iteration.\n",
       "    See the `IO Tools docs\n",
       "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
       "    for more information on ``iterator`` and ``chunksize``.\n",
       "\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "       ``TextFileReader`` is a context manager.\n",
       "compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer' and\n",
       "    `filepath_or_buffer` is path-like, then detect compression from the\n",
       "    following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
       "    decompression). If using 'zip', the ZIP file must contain only one data\n",
       "    file to be read in. Set to None for no decompression.\n",
       "thousands : str, optional\n",
       "    Thousands separator.\n",
       "decimal : str, default '.'\n",
       "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
       "lineterminator : str (length 1), optional\n",
       "    Character to break file into lines. Only valid with C parser.\n",
       "quotechar : str (length 1), optional\n",
       "    The character used to denote the start and end of a quoted item. Quoted\n",
       "    items can include the delimiter and it will be ignored.\n",
       "quoting : int or csv.QUOTE_* instance, default 0\n",
       "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
       "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
       "doublequote : bool, default ``True``\n",
       "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
       "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
       "   field as a single ``quotechar`` element.\n",
       "escapechar : str (length 1), optional\n",
       "    One-character string used to escape other characters.\n",
       "comment : str, optional\n",
       "    Indicates remainder of line should not be parsed. If found at the beginning\n",
       "    of a line, the line will be ignored altogether. This parameter must be a\n",
       "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
       "    fully commented lines are ignored by the parameter `header` but not by\n",
       "    `skiprows`. For example, if ``comment='#'``, parsing\n",
       "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
       "    treated as the header.\n",
       "encoding : str, optional\n",
       "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
       "    standard encodings\n",
       "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "       When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
       "       ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
       "       This behavior was previously only the case for ``engine=\"python\"``.\n",
       "dialect : str or csv.Dialect, optional\n",
       "    If provided, this parameter will override values (default or not) for the\n",
       "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
       "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
       "    override values, a ParserWarning will be issued. See csv.Dialect\n",
       "    documentation for more details.\n",
       "error_bad_lines : bool, default True\n",
       "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
       "    default cause an exception to be raised, and no DataFrame will be returned.\n",
       "    If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
       "    returned.\n",
       "warn_bad_lines : bool, default True\n",
       "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
       "    \"bad line\" will be output.\n",
       "delim_whitespace : bool, default False\n",
       "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
       "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
       "    is set to True, nothing should be passed in for the ``delimiter``\n",
       "    parameter.\n",
       "low_memory : bool, default True\n",
       "    Internally process the file in chunks, resulting in lower memory use\n",
       "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
       "    types either set False, or specify the type with the `dtype` parameter.\n",
       "    Note that the entire file is read into a single DataFrame regardless,\n",
       "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
       "    (Only valid with C parser).\n",
       "memory_map : bool, default False\n",
       "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
       "    directly onto memory and access the data directly from there. Using this\n",
       "    option can improve performance because there is no longer any I/O overhead.\n",
       "float_precision : str, optional\n",
       "    Specifies which converter the C engine should use for floating-point\n",
       "    values. The options are ``None`` or 'high' for the ordinary converter,\n",
       "    'legacy' for the original lower precision pandas converter, and\n",
       "    'round_trip' for the round-trip converter.\n",
       "\n",
       "    .. versionchanged:: 1.2\n",
       "\n",
       "storage_options : dict, optional\n",
       "    Extra options that make sense for a particular storage connection, e.g.\n",
       "    host, port, username, password, etc., if using a URL that will\n",
       "    be parsed by ``fsspec``, e.g., starting \"s3://\", \"gcs://\". An error\n",
       "    will be raised if providing this argument with a non-fsspec URL.\n",
       "    See the fsspec and backend storage implementation docs for the set of\n",
       "    allowed keys and values.\n",
       "\n",
       "    .. versionadded:: 1.2\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or TextParser\n",
       "    A comma-separated values (csv) file is returned as two-dimensional\n",
       "    data structure with labeled axes.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
       "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
       "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\unisse\\anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\io\\parsers.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mconvert_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmangle_dupe_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Read an Excel file into a pandas DataFrame.\n",
       "\n",
       "Supports `xls`, `xlsx`, `xlsm`, `xlsb`, `odf`, `ods` and `odt` file extensions\n",
       "read from a local filesystem or URL. Supports an option to read\n",
       "a single sheet or a list of sheets.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\n",
       "    Any valid string path is acceptable. The string could be a URL. Valid\n",
       "    URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
       "    expected. A local file could be: ``file://localhost/path/to/table.xlsx``.\n",
       "\n",
       "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
       "\n",
       "    By file-like object, we refer to objects with a ``read()`` method,\n",
       "    such as a file handle (e.g. via builtin ``open`` function)\n",
       "    or ``StringIO``.\n",
       "sheet_name : str, int, list, or None, default 0\n",
       "    Strings are used for sheet names. Integers are used in zero-indexed\n",
       "    sheet positions. Lists of strings/integers are used to request\n",
       "    multiple sheets. Specify None to get all sheets.\n",
       "\n",
       "    Available cases:\n",
       "\n",
       "    * Defaults to ``0``: 1st sheet as a `DataFrame`\n",
       "    * ``1``: 2nd sheet as a `DataFrame`\n",
       "    * ``\"Sheet1\"``: Load sheet with name \"Sheet1\"\n",
       "    * ``[0, 1, \"Sheet5\"]``: Load first, second and sheet named \"Sheet5\"\n",
       "      as a dict of `DataFrame`\n",
       "    * None: All sheets.\n",
       "\n",
       "header : int, list of int, default 0\n",
       "    Row (0-indexed) to use for the column labels of the parsed\n",
       "    DataFrame. If a list of integers is passed those row positions will\n",
       "    be combined into a ``MultiIndex``. Use None if there is no header.\n",
       "names : array-like, default None\n",
       "    List of column names to use. If file contains no header row,\n",
       "    then you should explicitly pass header=None.\n",
       "index_col : int, list of int, default None\n",
       "    Column (0-indexed) to use as the row labels of the DataFrame.\n",
       "    Pass None if there is no such column.  If a list is passed,\n",
       "    those columns will be combined into a ``MultiIndex``.  If a\n",
       "    subset of data is selected with ``usecols``, index_col\n",
       "    is based on the subset.\n",
       "usecols : int, str, list-like, or callable default None\n",
       "    * If None, then parse all columns.\n",
       "    * If str, then indicates comma separated list of Excel column letters\n",
       "      and column ranges (e.g. \"A:E\" or \"A,C,E:F\"). Ranges are inclusive of\n",
       "      both sides.\n",
       "    * If list of int, then indicates list of column numbers to be parsed.\n",
       "    * If list of string, then indicates list of column names to be parsed.\n",
       "\n",
       "      .. versionadded:: 0.24.0\n",
       "\n",
       "    * If callable, then evaluate each column name against it and parse the\n",
       "      column if the callable returns ``True``.\n",
       "\n",
       "    Returns a subset of the columns according to behavior above.\n",
       "\n",
       "      .. versionadded:: 0.24.0\n",
       "\n",
       "squeeze : bool, default False\n",
       "    If the parsed data only contains one column then return a Series.\n",
       "dtype : Type name or dict of column -> type, default None\n",
       "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
       "    Use `object` to preserve data as stored in Excel and not interpret dtype.\n",
       "    If converters are specified, they will be applied INSTEAD\n",
       "    of dtype conversion.\n",
       "engine : str, default None\n",
       "    If io is not a buffer or path, this must be set to identify io.\n",
       "    Supported engines: \"xlrd\", \"openpyxl\", \"odf\", \"pyxlsb\".\n",
       "    Engine compatibility :\n",
       "\n",
       "    - \"xlrd\" supports old-style Excel files (.xls).\n",
       "    - \"openpyxl\" supports newer Excel file formats.\n",
       "    - \"odf\" supports OpenDocument file formats (.odf, .ods, .odt).\n",
       "    - \"pyxlsb\" supports Binary Excel files.\n",
       "\n",
       "    .. versionchanged:: 1.2.0\n",
       "        The engine `xlrd <https://xlrd.readthedocs.io/en/latest/>`_\n",
       "        now only supports old-style ``.xls`` files.\n",
       "        When ``engine=None``, the following logic will be\n",
       "        used to determine the engine:\n",
       "\n",
       "       - If ``path_or_buffer`` is an OpenDocument format (.odf, .ods, .odt),\n",
       "         then `odf <https://pypi.org/project/odfpy/>`_ will be used.\n",
       "       - Otherwise if ``path_or_buffer`` is an xls format,\n",
       "         ``xlrd`` will be used.\n",
       "       - Otherwise if `openpyxl <https://pypi.org/project/openpyxl/>`_ is installed,\n",
       "         then ``openpyxl`` will be used.\n",
       "       - Otherwise if ``xlrd >= 2.0`` is installed, a ``ValueError`` will be raised.\n",
       "       - Otherwise ``xlrd`` will be used and a ``FutureWarning`` will be raised. This\n",
       "         case will raise a ``ValueError`` in a future version of pandas.\n",
       "\n",
       "converters : dict, default None\n",
       "    Dict of functions for converting values in certain columns. Keys can\n",
       "    either be integers or column labels, values are functions that take one\n",
       "    input argument, the Excel cell content, and return the transformed\n",
       "    content.\n",
       "true_values : list, default None\n",
       "    Values to consider as True.\n",
       "false_values : list, default None\n",
       "    Values to consider as False.\n",
       "skiprows : list-like, int, or callable, optional\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (int) at the\n",
       "    start of the file. If callable, the callable function will be evaluated\n",
       "    against the row indices, returning True if the row should be skipped and\n",
       "    False otherwise. An example of a valid callable argument would be ``lambda\n",
       "    x: x in [0, 2]``.\n",
       "nrows : int, default None\n",
       "    Number of rows to parse.\n",
       "na_values : scalar, str, list-like, or dict, default None\n",
       "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
       "    per-column NA values. By default the following values are interpreted\n",
       "    as NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
       "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
       "    'nan', 'null'.\n",
       "keep_default_na : bool, default True\n",
       "    Whether or not to include the default NaN values when parsing the data.\n",
       "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
       "\n",
       "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
       "      is appended to the default NaN values used for parsing.\n",
       "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
       "      the default NaN values are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
       "      the NaN values specified `na_values` are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
       "      strings will be parsed as NaN.\n",
       "\n",
       "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
       "    `na_values` parameters will be ignored.\n",
       "na_filter : bool, default True\n",
       "    Detect missing value markers (empty strings and the value of na_values). In\n",
       "    data without any NAs, passing na_filter=False can improve the performance\n",
       "    of reading a large file.\n",
       "verbose : bool, default False\n",
       "    Indicate number of NA values placed in non-numeric columns.\n",
       "parse_dates : bool, list-like, or dict, default False\n",
       "    The behavior is as follows:\n",
       "\n",
       "    * bool. If True -> try parsing the index.\n",
       "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
       "      a single date column.\n",
       "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
       "      result 'foo'\n",
       "\n",
       "    If a column or index contains an unparseable date, the entire column or\n",
       "    index will be returned unaltered as an object data type. If you don`t want to\n",
       "    parse some cells as date just change their type in Excel to \"Text\".\n",
       "    For non-standard datetime parsing, use ``pd.to_datetime`` after ``pd.read_excel``.\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "date_parser : function, optional\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by `parse_dates` into a single array\n",
       "    and pass that; and 3) call `date_parser` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
       "    arguments.\n",
       "thousands : str, default None\n",
       "    Thousands separator for parsing string columns to numeric.  Note that\n",
       "    this parameter is only necessary for columns stored as TEXT in Excel,\n",
       "    any numeric columns will automatically be parsed, regardless of display\n",
       "    format.\n",
       "comment : str, default None\n",
       "    Comments out remainder of line. Pass a character or characters to this\n",
       "    argument to indicate comments in the input file. Any data between the\n",
       "    comment string and the end of the current line is ignored.\n",
       "skipfooter : int, default 0\n",
       "    Rows at the end to skip (0-indexed).\n",
       "convert_float : bool, default True\n",
       "    Convert integral floats to int (i.e., 1.0 --> 1). If False, all numeric\n",
       "    data will be read in as floats: Excel stores all numbers as floats\n",
       "    internally.\n",
       "mangle_dupe_cols : bool, default True\n",
       "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
       "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
       "    are duplicate names in the columns.\n",
       "storage_options : dict, optional\n",
       "    Extra options that make sense for a particular storage connection, e.g.\n",
       "    host, port, username, password, etc., if using a URL that will\n",
       "    be parsed by ``fsspec``, e.g., starting \"s3://\", \"gcs://\". An error\n",
       "    will be raised if providing this argument with a local path or\n",
       "    a file-like buffer. See the fsspec and backend storage implementation\n",
       "    docs for the set of allowed keys and values.\n",
       "\n",
       "    .. versionadded:: 1.2.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or dict of DataFrames\n",
       "    DataFrame from the passed in Excel file. See notes in sheet_name\n",
       "    argument for more information on when a dict of DataFrames is returned.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.to_excel : Write DataFrame to an Excel file.\n",
       "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
       "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
       "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "The file can be read using the file name as string or an open file object:\n",
       "\n",
       ">>> pd.read_excel('tmp.xlsx', index_col=0)  # doctest: +SKIP\n",
       "       Name  Value\n",
       "0   string1      1\n",
       "1   string2      2\n",
       "2  #Comment      3\n",
       "\n",
       ">>> pd.read_excel(open('tmp.xlsx', 'rb'),\n",
       "...               sheet_name='Sheet3')  # doctest: +SKIP\n",
       "   Unnamed: 0      Name  Value\n",
       "0           0   string1      1\n",
       "1           1   string2      2\n",
       "2           2  #Comment      3\n",
       "\n",
       "Index and header can be specified via the `index_col` and `header` arguments\n",
       "\n",
       ">>> pd.read_excel('tmp.xlsx', index_col=None, header=None)  # doctest: +SKIP\n",
       "     0         1      2\n",
       "0  NaN      Name  Value\n",
       "1  0.0   string1      1\n",
       "2  1.0   string2      2\n",
       "3  2.0  #Comment      3\n",
       "\n",
       "Column types are inferred but can be explicitly specified\n",
       "\n",
       ">>> pd.read_excel('tmp.xlsx', index_col=0,\n",
       "...               dtype={'Name': str, 'Value': float})  # doctest: +SKIP\n",
       "       Name  Value\n",
       "0   string1    1.0\n",
       "1   string2    2.0\n",
       "2  #Comment    3.0\n",
       "\n",
       "True, False, and NA values, and thousands separators have defaults,\n",
       "but can be explicitly specified, too. Supply the values you would like\n",
       "as strings or lists of strings!\n",
       "\n",
       ">>> pd.read_excel('tmp.xlsx', index_col=0,\n",
       "...               na_values=['string1', 'string2'])  # doctest: +SKIP\n",
       "       Name  Value\n",
       "0       NaN      1\n",
       "1       NaN      2\n",
       "2  #Comment      3\n",
       "\n",
       "Comment lines in the excel input file can be skipped using the `comment` kwarg\n",
       "\n",
       ">>> pd.read_excel('tmp.xlsx', index_col=0, comment='#')  # doctest: +SKIP\n",
       "      Name  Value\n",
       "0  string1    1.0\n",
       "1  string2    2.0\n",
       "2     None    NaN\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\unisse\\anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\io\\excel\\_base.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_excel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>school_name</th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>municipality</th>\n",
       "      <th>division</th>\n",
       "      <th>district</th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101746</td>\n",
       "      <td>A. Diaz, Sr. ES</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Pangasinan</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>Pangasinan II, Binalonan</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102193</td>\n",
       "      <td>A. P. Santos ES (SPED Center)</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Laoag City (Capital)</td>\n",
       "      <td>Laoag City</td>\n",
       "      <td>Laoag City District II</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101283</td>\n",
       "      <td>A.P. Guevarra IS</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Pangasinan</td>\n",
       "      <td>Bayambang</td>\n",
       "      <td>Pangasinan I, Lingayen</td>\n",
       "      <td>Bayambang II</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100216</td>\n",
       "      <td>Ab-Abut ES</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Piddig</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Piddig</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100043</td>\n",
       "      <td>Abaca ES</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bangui</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bangui</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id                    school_name             region      province  \\\n",
       "0     101746                A. Diaz, Sr. ES  I (Ilocos Region)    Pangasinan   \n",
       "1     102193  A. P. Santos ES (SPED Center)  I (Ilocos Region)  Ilocos Norte   \n",
       "2     101283               A.P. Guevarra IS  I (Ilocos Region)    Pangasinan   \n",
       "3     100216                     Ab-Abut ES  I (Ilocos Region)  Ilocos Norte   \n",
       "4     100043                       Abaca ES  I (Ilocos Region)  Ilocos Norte   \n",
       "\n",
       "           municipality                  division                district  \\\n",
       "0              Bautista  Pangasinan II, Binalonan                Bautista   \n",
       "1  Laoag City (Capital)                Laoag City  Laoag City District II   \n",
       "2             Bayambang    Pangasinan I, Lingayen            Bayambang II   \n",
       "3                Piddig              Ilocos Norte                  Piddig   \n",
       "4                Bangui              Ilocos Norte                  Bangui   \n",
       "\n",
       "  year_level gender  enrollment  \n",
       "0    grade 1   male          53  \n",
       "1    grade 1   male          31  \n",
       "2    grade 1   male          16  \n",
       "3    grade 1   male          19  \n",
       "4    grade 1   male          12  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default, the encoding is utf-8, but since the data has some latin characters\n",
    "# the encoding argument needs to be updated\n",
    "deped2012 = pd.read_csv(DSDATA / 'deped_publicelementaryenrollment2012.csv', encoding='latin1')\n",
    "\n",
    "# the head function provides a preview of the first 5 rows of the data\n",
    "deped2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>municipality</th>\n",
       "      <th>division</th>\n",
       "      <th>school_id</th>\n",
       "      <th>school_name</th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100001</td>\n",
       "      <td>Apaleng-libtong ES</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>18.253666</td>\n",
       "      <td>120.60618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100002</td>\n",
       "      <td>Bacarra CES</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>41</td>\n",
       "      <td>18.25096389</td>\n",
       "      <td>120.6089583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100003</td>\n",
       "      <td>Buyon ES</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "      <td>18.234599</td>\n",
       "      <td>120.616037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100004</td>\n",
       "      <td>Ganagan Elementary School</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>8</td>\n",
       "      <td>18.25001389</td>\n",
       "      <td>120.5871694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100005</td>\n",
       "      <td>Macupit ES</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>5</td>\n",
       "      <td>18.29399444</td>\n",
       "      <td>120.6410194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     region      province municipality      division  \\\n",
       "0  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "1  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "2  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "3  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "4  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "\n",
       "   school_id                school_name year_level gender  enrollment  \\\n",
       "0     100001         Apaleng-libtong ES    grade 1   male           9   \n",
       "1     100002                Bacarra CES    grade 1   male          41   \n",
       "2     100003                   Buyon ES    grade 1   male           7   \n",
       "3     100004  Ganagan Elementary School    grade 1   male           8   \n",
       "4     100005                 Macupit ES    grade 1   male           5   \n",
       "\n",
       "      latitude    longitude  \n",
       "0    18.253666    120.60618  \n",
       "1  18.25096389  120.6089583  \n",
       "2    18.234599   120.616037  \n",
       "3  18.25001389  120.5871694  \n",
       "4  18.29399444  120.6410194  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in the other file too\n",
    "deped2015 = pd.read_csv(DSDATA / 'depend_publicelementaryenrollment2015.csv', encoding='latin1')\n",
    "deped2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's begin exploring the data...\n",
    "\n",
    "* How many rows and columns do we have? \n",
    "* What is the data type of each column? \n",
    "* What is the most common value? Mean? Standard deviation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `shape`\n",
    "\n",
    "A `pandas` `DataFrame` is essentially a 2D `numpy` array. Using the `shape` attribute of the `DataFrame`, we can easily check the dimensions of the data file we read. It returns a tuple of the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463908, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396288, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dtypes` \n",
    "`dtypes` lets you check what data type each column is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_id        int64\n",
       "school_name     object\n",
       "region          object\n",
       "province        object\n",
       "municipality    object\n",
       "division        object\n",
       "district        object\n",
       "year_level      object\n",
       "gender          object\n",
       "enrollment       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region          object\n",
       "province        object\n",
       "municipality    object\n",
       "division        object\n",
       "school_id        int64\n",
       "school_name     object\n",
       "year_level      object\n",
       "gender          object\n",
       "enrollment       int64\n",
       "latitude        object\n",
       "longitude       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `describe()`\n",
    "`describe()` provides the basic descriptive statistics of the`DataFrame`. By default, it only includes the columns with numerical data. Non-numerical columns are omitted but there are arguments that shows the statistics related to non-numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>463908.000000</td>\n",
       "      <td>463908.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>123102.439820</td>\n",
       "      <td>28.582152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22010.932343</td>\n",
       "      <td>44.727529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>109747.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>119533.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>129325.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>261503.000000</td>\n",
       "      <td>1047.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           school_id     enrollment\n",
       "count  463908.000000  463908.000000\n",
       "mean   123102.439820      28.582152\n",
       "std     22010.932343      44.727529\n",
       "min    100001.000000       0.000000\n",
       "25%    109747.000000       9.000000\n",
       "50%    119533.000000      16.000000\n",
       "75%    129325.000000      31.000000\n",
       "max    261503.000000    1047.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_name</th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>municipality</th>\n",
       "      <th>division</th>\n",
       "      <th>district</th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>29699</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>1437</td>\n",
       "      <td>206</td>\n",
       "      <td>2415</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>San Isidro ES</td>\n",
       "      <td>VIII (Eastern Visayas)</td>\n",
       "      <td>Leyte</td>\n",
       "      <td>Davao City</td>\n",
       "      <td>Leyte</td>\n",
       "      <td>Rizal</td>\n",
       "      <td>grade 2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2328</td>\n",
       "      <td>43728</td>\n",
       "      <td>15612</td>\n",
       "      <td>3420</td>\n",
       "      <td>14136</td>\n",
       "      <td>1608</td>\n",
       "      <td>77318</td>\n",
       "      <td>231954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          school_name                  region province municipality division  \\\n",
       "count          463908                  463908   463908       463908   463908   \n",
       "unique          29699                      17       86         1437      206   \n",
       "top     San Isidro ES  VIII (Eastern Visayas)    Leyte   Davao City    Leyte   \n",
       "freq             2328                   43728    15612         3420    14136   \n",
       "\n",
       "       district year_level  gender  \n",
       "count    463908     463908  463908  \n",
       "unique     2415          6       2  \n",
       "top       Rizal    grade 2  female  \n",
       "freq       1608      77318  231954  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.describe(include=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "\n",
    "After looking at the basic information about the data, let's see how \"clean\" the data is\n",
    "\n",
    "#### Common Data Problems (from slides)\n",
    "1. Missing values\n",
    "2. Formatting issues / data types\n",
    "3. Duplicate records\n",
    "4. Varying representation / Handle categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `isna()` / `isnull()`\n",
    "\n",
    "To check if there's any missing values, `pandas` provides these two functions to detect them. This actually maps each individual cell to either True or False.\n",
    "\n",
    "#### `dropna()`\n",
    "\n",
    "To remove any records with missing values, `dropna()` may be used. It has a number of arguments to help narrow down the criteria for removing the records with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_id       0\n",
       "school_name     0\n",
       "region          0\n",
       "province        0\n",
       "municipality    0\n",
       "division        0\n",
       "district        0\n",
       "year_level      0\n",
       "gender          0\n",
       "enrollment      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mdeped2012\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'any'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mthresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Remove missing values.\n",
       "\n",
       "See the :ref:`User Guide <missing_data>` for more on which values are\n",
       "considered missing, and how to work with missing data.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
       "    Determine if rows or columns which contain missing values are\n",
       "    removed.\n",
       "\n",
       "    * 0, or 'index' : Drop rows which contain missing values.\n",
       "    * 1, or 'columns' : Drop columns which contain missing value.\n",
       "\n",
       "    .. versionchanged:: 1.0.0\n",
       "\n",
       "       Pass tuple or list to drop on multiple axes.\n",
       "       Only a single axis is allowed.\n",
       "\n",
       "how : {'any', 'all'}, default 'any'\n",
       "    Determine if row or column is removed from DataFrame, when we have\n",
       "    at least one NA or all NA.\n",
       "\n",
       "    * 'any' : If any NA values are present, drop that row or column.\n",
       "    * 'all' : If all values are NA, drop that row or column.\n",
       "\n",
       "thresh : int, optional\n",
       "    Require that many non-NA values.\n",
       "subset : array-like, optional\n",
       "    Labels along other axis to consider, e.g. if you are dropping rows\n",
       "    these would be a list of columns to include.\n",
       "inplace : bool, default False\n",
       "    If True, do operation inplace and return None.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or None\n",
       "    DataFrame with NA entries dropped from it or None if ``inplace=True``.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.isna: Indicate missing values.\n",
       "DataFrame.notna : Indicate existing (non-missing) values.\n",
       "DataFrame.fillna : Replace missing values.\n",
       "Series.dropna : Drop missing values.\n",
       "Index.dropna : Drop missing indices.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
       "...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
       "...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
       "...                             pd.NaT]})\n",
       ">>> df\n",
       "       name        toy       born\n",
       "0    Alfred        NaN        NaT\n",
       "1    Batman  Batmobile 1940-04-25\n",
       "2  Catwoman   Bullwhip        NaT\n",
       "\n",
       "Drop the rows where at least one element is missing.\n",
       "\n",
       ">>> df.dropna()\n",
       "     name        toy       born\n",
       "1  Batman  Batmobile 1940-04-25\n",
       "\n",
       "Drop the columns where at least one element is missing.\n",
       "\n",
       ">>> df.dropna(axis='columns')\n",
       "       name\n",
       "0    Alfred\n",
       "1    Batman\n",
       "2  Catwoman\n",
       "\n",
       "Drop the rows where all elements are missing.\n",
       "\n",
       ">>> df.dropna(how='all')\n",
       "       name        toy       born\n",
       "0    Alfred        NaN        NaT\n",
       "1    Batman  Batmobile 1940-04-25\n",
       "2  Catwoman   Bullwhip        NaT\n",
       "\n",
       "Keep only the rows with at least 2 non-NA values.\n",
       "\n",
       ">>> df.dropna(thresh=2)\n",
       "       name        toy       born\n",
       "1    Batman  Batmobile 1940-04-25\n",
       "2  Catwoman   Bullwhip        NaT\n",
       "\n",
       "Define in which columns to look for missing values.\n",
       "\n",
       ">>> df.dropna(subset=['name', 'toy'])\n",
       "       name        toy       born\n",
       "1    Batman  Batmobile 1940-04-25\n",
       "2  Catwoman   Bullwhip        NaT\n",
       "\n",
       "Keep the DataFrame with valid entries in the same variable.\n",
       "\n",
       ">>> df.dropna(inplace=True)\n",
       ">>> df\n",
       "     name        toy       born\n",
       "1  Batman  Batmobile 1940-04-25\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\unisse\\anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\core\\frame.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deped2012.dropna?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `duplicated()` --> `drop_duplicates()`\n",
    "\n",
    "The `duplicated()` function returns the duplicated rows in the `DataFrame`. It also has a number of arguments for you to specify the subset of columns. \n",
    "\n",
    "`drop_duplicates()` is the function to remove the duplicated rows found by `duplicated()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_id', 'school_name', 'region', 'province', 'municipality',\n",
       "       'division', 'district', 'year_level', 'gender', 'enrollment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231954"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.duplicated(subset=['school_id', 'school_name', 'region', 'province', 'municipality',\n",
    "       'division', 'district', 'year_level']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>school_name</th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>municipality</th>\n",
       "      <th>division</th>\n",
       "      <th>district</th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31716</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70375</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>female</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109034</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 2</td>\n",
       "      <td>male</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147693</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 2</td>\n",
       "      <td>female</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186352</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 3</td>\n",
       "      <td>male</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225011</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 3</td>\n",
       "      <td>female</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263670</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 4</td>\n",
       "      <td>male</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302329</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 4</td>\n",
       "      <td>female</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340988</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 5</td>\n",
       "      <td>male</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379647</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 5</td>\n",
       "      <td>female</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418306</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456965</th>\n",
       "      <td>130114</td>\n",
       "      <td>Katipunan ES</td>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala</td>\n",
       "      <td>North Cotabato</td>\n",
       "      <td>Makilala North</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>female</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        school_id   school_name              region        province  \\\n",
       "31716      130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "70375      130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "109034     130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "147693     130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "186352     130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "225011     130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "263670     130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "302329     130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "340988     130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "379647     130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "418306     130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "456965     130114  Katipunan ES  XII (SOCCSKSARGEN)  North Cotabato   \n",
       "\n",
       "       municipality        division        district year_level  gender  \\\n",
       "31716      Makilala  North Cotabato  Makilala North    grade 1    male   \n",
       "70375      Makilala  North Cotabato  Makilala North    grade 1  female   \n",
       "109034     Makilala  North Cotabato  Makilala North    grade 2    male   \n",
       "147693     Makilala  North Cotabato  Makilala North    grade 2  female   \n",
       "186352     Makilala  North Cotabato  Makilala North    grade 3    male   \n",
       "225011     Makilala  North Cotabato  Makilala North    grade 3  female   \n",
       "263670     Makilala  North Cotabato  Makilala North    grade 4    male   \n",
       "302329     Makilala  North Cotabato  Makilala North    grade 4  female   \n",
       "340988     Makilala  North Cotabato  Makilala North    grade 5    male   \n",
       "379647     Makilala  North Cotabato  Makilala North    grade 5  female   \n",
       "418306     Makilala  North Cotabato  Makilala North    grade 6    male   \n",
       "456965     Makilala  North Cotabato  Makilala North    grade 6  female   \n",
       "\n",
       "        enrollment  \n",
       "31716           19  \n",
       "70375           11  \n",
       "109034          11  \n",
       "147693          11  \n",
       "186352           8  \n",
       "225011          11  \n",
       "263670          12  \n",
       "302329          12  \n",
       "340988          11  \n",
       "379647           7  \n",
       "418306           7  \n",
       "456965          12  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012[deped2012.duplicated(subset=['school_name', 'region', 'province', 'municipality',\n",
    "       'division', 'district', 'year_level', 'gender'], keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mdeped2012\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Optional[Union[Hashable, Sequence[Hashable]]]'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Union[str, bool]'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'first'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'Optional[DataFrame]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return DataFrame with duplicate rows removed.\n",
       "\n",
       "Considering certain columns is optional. Indexes, including time indexes\n",
       "are ignored.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "subset : column label or sequence of labels, optional\n",
       "    Only consider certain columns for identifying duplicates, by\n",
       "    default use all of the columns.\n",
       "keep : {'first', 'last', False}, default 'first'\n",
       "    Determines which duplicates (if any) to keep.\n",
       "    - ``first`` : Drop duplicates except for the first occurrence.\n",
       "    - ``last`` : Drop duplicates except for the last occurrence.\n",
       "    - False : Drop all duplicates.\n",
       "inplace : bool, default False\n",
       "    Whether to drop duplicates in place or to return a copy.\n",
       "ignore_index : bool, default False\n",
       "    If True, the resulting axis will be labeled 0, 1, , n - 1.\n",
       "\n",
       "    .. versionadded:: 1.0.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or None\n",
       "    DataFrame with duplicates removed or None if ``inplace=True``.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.value_counts: Count unique combinations of columns.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Consider dataset containing ramen rating.\n",
       "\n",
       ">>> df = pd.DataFrame({\n",
       "...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
       "...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
       "...     'rating': [4, 4, 3.5, 15, 5]\n",
       "... })\n",
       ">>> df\n",
       "    brand style  rating\n",
       "0  Yum Yum   cup     4.0\n",
       "1  Yum Yum   cup     4.0\n",
       "2  Indomie   cup     3.5\n",
       "3  Indomie  pack    15.0\n",
       "4  Indomie  pack     5.0\n",
       "\n",
       "By default, it removes duplicate rows based on all columns.\n",
       "\n",
       ">>> df.drop_duplicates()\n",
       "    brand style  rating\n",
       "0  Yum Yum   cup     4.0\n",
       "2  Indomie   cup     3.5\n",
       "3  Indomie  pack    15.0\n",
       "4  Indomie  pack     5.0\n",
       "\n",
       "To remove duplicates on specific column(s), use ``subset``.\n",
       "\n",
       ">>> df.drop_duplicates(subset=['brand'])\n",
       "    brand style  rating\n",
       "0  Yum Yum   cup     4.0\n",
       "2  Indomie   cup     3.5\n",
       "\n",
       "To remove duplicates and keep last occurrences, use ``keep``.\n",
       "\n",
       ">>> df.drop_duplicates(subset=['brand', 'style'], keep='last')\n",
       "    brand style  rating\n",
       "1  Yum Yum   cup     4.0\n",
       "2  Indomie   cup     3.5\n",
       "4  Indomie  pack     5.0\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\unisse\\anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\core\\frame.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deped2012.drop_duplicates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varying representation\n",
    "\n",
    "For categorical or textual data, unless the options provided are fixed, misspellings and different representations may exist in the same file.\n",
    "\n",
    "To check the unique values of each column, a `pandas` `Series` has a function `unique()` which returns all the unique values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pangasinan', 'Ilocos Norte', 'Ilocos Sur', 'La Union', 'Isabela',\n",
       "       'Nueva Vizcaya', 'Cagayan', 'Quirino', 'Batanes', 'Nueva Ecija',\n",
       "       'Bataan', 'Bulacan', 'Aurora', 'Zambales', 'Tarlac', 'Pampanga',\n",
       "       'Batangas', 'Quezon', 'Laguna', 'Rizal', 'Cavite', 'Palawan',\n",
       "       'Oriental Mindoro', 'Occidental Mindoro', 'Romblon', 'Marinduque',\n",
       "       'Camarines Sur', 'Camarines Norte', 'Masbate', 'Sorsogon', 'Albay',\n",
       "       'Catanduanes', 'Negros Occidental', 'Iloilo', 'Antique', 'Capiz',\n",
       "       'Aklan', 'Guimaras', 'Bohol', 'Negros Oriental', 'Cebu',\n",
       "       'Siquijor', 'Eastern Samar', 'Leyte', 'Western Samar',\n",
       "       'Northern Samar', 'Southern Leyte', 'Biliran', 'Zamboanga del Sur',\n",
       "       'Zamboanga Sibugay', 'Zamboanga del Norte', 'City of Isabela',\n",
       "       'Misamis Occidental', 'Lanao del Norte', 'Misamis Oriental',\n",
       "       'Bukidnon', 'Camiguin', 'Davao del Sur', 'Davao del Norte',\n",
       "       'Davao Oriental', 'Compostela Valley', 'South Cotabato',\n",
       "       'Sarangani', 'North Cotabato', 'Sultan Kudarat',\n",
       "       'City of Cotabato', 'Surigao del Sur', 'Agusan del Norte',\n",
       "       'Dinagat Islands', 'Surigao del Norte', 'Agusan del Sur',\n",
       "       'Lanao del Sur', 'Sulu', 'Tawi-Tawi', 'Basilan', 'Maguindanao',\n",
       "       'Kalinga', 'Ifugao', 'Abra', 'Mountain Province', 'Benguet',\n",
       "       'Apayao', 'NCR Second District', 'NCR Third District',\n",
       "       'NCR Fourth District', 'Manila, NCR, First District'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012['province'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['grade 1', 'grade 2', 'grade 3', 'grade 4', 'grade 5', 'grade 6'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012['year_level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I (Ilocos Region)', 'II (Cagayan Valley)', 'III (Central Luzon)',\n",
       "       'IV-A (CALABARZON)', 'IV-B (MIMAROPA)', 'V (Bicol Region)',\n",
       "       'VI (Western Visayas)', 'VII (Central Visayas)',\n",
       "       'VIII (Eastern Visayas)', 'IX (Zamboanga Peninsula)',\n",
       "       'X (Northern Mindanao)', 'XI (Davao Region)', 'XII (SOCCSKSARGEN)',\n",
       "       'XIII (Caraga)', 'ARMM (Autonomous Region in Muslim Mindanao)',\n",
       "       'CAR (Cordillera Administrative Region)',\n",
       "       'NCR (National Capital Region)'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Region I - Ilocos Region', 'Region II - Cagayan Valley',\n",
       "       'Region III - Central Luzon', 'Region IV-A - CALABARZON',\n",
       "       'Region IV-B - MIMAROPA', 'Region V - Bicol Region',\n",
       "       'Region VI - Western Visayas', 'Region VII - Central Visayas',\n",
       "       'Region VIII - Eastern Visayas', 'Region IX - Zamboanga Peninsula',\n",
       "       'Region X - Northern Mindanao', 'Region XI - Davao Region',\n",
       "       'Region XII - SOCCSKSARGEN', 'CARAGA - CARAGA',\n",
       "       'ARMM - Autonomous Region in Muslim Mindanao'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015['region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing Data\n",
    "\n",
    "High data granularity is great for a detailed analysis. However, data is usually summarized or aggregated prior to visualization. `pandas` also provides an easy way to summarize data based on the columns you'd like using the `groupby` function.\n",
    "\n",
    "We can call any of the following when grouping by columns:\n",
    "- count()\n",
    "- sum()\n",
    "- min()\n",
    "- max()\n",
    "- std()\n",
    "\n",
    "For columns that are categorical in nature, we can simply do `df['column'].value_counts()`. This will give the frequency of each unique value in the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region VIII - Eastern Visayas                  41484\n",
       "Region VI - Western Visayas                    39204\n",
       "Region V - Bicol Region                        35892\n",
       "Region VII - Central Visayas                   33768\n",
       "Region III - Central Luzon                     33336\n",
       "Region IV-A - CALABARZON                       31452\n",
       "Region I - Ilocos Region                       27648\n",
       "Region II - Cagayan Valley                     24924\n",
       "Region IX - Zamboanga Peninsula                23724\n",
       "Region X - Northern Mindanao                   23532\n",
       "Region IV-B - MIMAROPA                         20232\n",
       "Region XI - Davao Region                       18420\n",
       "CARAGA - CARAGA                                18408\n",
       "Region XII - SOCCSKSARGEN                      18228\n",
       "ARMM - Autonomous Region in Muslim Mindanao     6036\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.Series.value_counts()\n",
    "\n",
    "deped2015['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VIII (Eastern Visayas)                         43728\n",
       "VI (Western Visayas)                           40788\n",
       "V (Bicol Region)                               37704\n",
       "III (Central Luzon)                            35796\n",
       "VII (Central Visayas)                          35196\n",
       "IV-A (CALABARZON)                              32724\n",
       "I (Ilocos Region)                              28728\n",
       "ARMM (Autonomous Region in Muslim Mindanao)    26376\n",
       "II (Cagayan Valley)                            26304\n",
       "IX (Zamboanga Peninsula)                       25080\n",
       "X (Northern Mindanao)                          25032\n",
       "IV-B (MIMAROPA)                                22020\n",
       "XII (SOCCSKSARGEN)                             20484\n",
       "XIII (Caraga)                                  19968\n",
       "XI (Davao Region)                              19584\n",
       "CAR (Cordillera Administrative Region)         18180\n",
       "NCR (National Capital Region)                   6216\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463908"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deped2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mdeped2012\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mas_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgroup_keys\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msqueeze\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mobject\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[1;36m0x00000217533E1F50\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobserved\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdropna\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrameGroupBy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Group DataFrame using a mapper or by a Series of columns.\n",
       "\n",
       "A groupby operation involves some combination of splitting the\n",
       "object, applying a function, and combining the results. This can be\n",
       "used to group large amounts of data and compute operations on these\n",
       "groups.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "by : mapping, function, label, or list of labels\n",
       "    Used to determine the groups for the groupby.\n",
       "    If ``by`` is a function, it's called on each value of the object's\n",
       "    index. If a dict or Series is passed, the Series or dict VALUES\n",
       "    will be used to determine the groups (the Series' values are first\n",
       "    aligned; see ``.align()`` method). If an ndarray is passed, the\n",
       "    values are used as-is to determine the groups. A label or list of\n",
       "    labels may be passed to group by the columns in ``self``. Notice\n",
       "    that a tuple is interpreted as a (single) key.\n",
       "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
       "    Split along rows (0) or columns (1).\n",
       "level : int, level name, or sequence of such, default None\n",
       "    If the axis is a MultiIndex (hierarchical), group by a particular\n",
       "    level or levels.\n",
       "as_index : bool, default True\n",
       "    For aggregated output, return object with group labels as the\n",
       "    index. Only relevant for DataFrame input. as_index=False is\n",
       "    effectively \"SQL-style\" grouped output.\n",
       "sort : bool, default True\n",
       "    Sort group keys. Get better performance by turning this off.\n",
       "    Note this does not influence the order of observations within each\n",
       "    group. Groupby preserves the order of rows within each group.\n",
       "group_keys : bool, default True\n",
       "    When calling apply, add group keys to index to identify pieces.\n",
       "squeeze : bool, default False\n",
       "    Reduce the dimensionality of the return type if possible,\n",
       "    otherwise return a consistent type.\n",
       "\n",
       "    .. deprecated:: 1.1.0\n",
       "\n",
       "observed : bool, default False\n",
       "    This only applies if any of the groupers are Categoricals.\n",
       "    If True: only show observed values for categorical groupers.\n",
       "    If False: show all values for categorical groupers.\n",
       "dropna : bool, default True\n",
       "    If True, and if group keys contain NA values, NA values together\n",
       "    with row/column will be dropped.\n",
       "    If False, NA values will also be treated as the key in groups\n",
       "\n",
       "    .. versionadded:: 1.1.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrameGroupBy\n",
       "    Returns a groupby object that contains information about the groups.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "resample : Convenience method for frequency conversion and resampling\n",
       "    of time series.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "See the `user guide\n",
       "<https://pandas.pydata.org/pandas-docs/stable/groupby.html>`_ for more.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
       "...                               'Parrot', 'Parrot'],\n",
       "...                    'Max Speed': [380., 370., 24., 26.]})\n",
       ">>> df\n",
       "   Animal  Max Speed\n",
       "0  Falcon      380.0\n",
       "1  Falcon      370.0\n",
       "2  Parrot       24.0\n",
       "3  Parrot       26.0\n",
       ">>> df.groupby(['Animal']).mean()\n",
       "        Max Speed\n",
       "Animal\n",
       "Falcon      375.0\n",
       "Parrot       25.0\n",
       "\n",
       "**Hierarchical Indexes**\n",
       "\n",
       "We can groupby different levels of a hierarchical index\n",
       "using the `level` parameter:\n",
       "\n",
       ">>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
       "...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
       ">>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
       ">>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
       "...                   index=index)\n",
       ">>> df\n",
       "                Max Speed\n",
       "Animal Type\n",
       "Falcon Captive      390.0\n",
       "       Wild         350.0\n",
       "Parrot Captive       30.0\n",
       "       Wild          20.0\n",
       ">>> df.groupby(level=0).mean()\n",
       "        Max Speed\n",
       "Animal\n",
       "Falcon      370.0\n",
       "Parrot       25.0\n",
       ">>> df.groupby(level=\"Type\").mean()\n",
       "         Max Speed\n",
       "Type\n",
       "Captive      210.0\n",
       "Wild         185.0\n",
       "\n",
       "We can also choose to include NA in group keys or not by setting\n",
       "`dropna` parameter, the default setting is `True`:\n",
       "\n",
       ">>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
       ">>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
       "\n",
       ">>> df.groupby(by=[\"b\"]).sum()\n",
       "    a   c\n",
       "b\n",
       "1.0 2   3\n",
       "2.0 2   5\n",
       "\n",
       ">>> df.groupby(by=[\"b\"], dropna=False).sum()\n",
       "    a   c\n",
       "b\n",
       "1.0 2   3\n",
       "2.0 2   5\n",
       "NaN 1   4\n",
       "\n",
       ">>> l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\n",
       ">>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
       "\n",
       ">>> df.groupby(by=\"a\").sum()\n",
       "    b     c\n",
       "a\n",
       "a   13.0   13.0\n",
       "b   12.3  123.0\n",
       "\n",
       ">>> df.groupby(by=\"a\", dropna=False).sum()\n",
       "    b     c\n",
       "a\n",
       "a   13.0   13.0\n",
       "b   12.3  123.0\n",
       "NaN 12.3   33.0\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\unisse\\anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\core\\frame.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deped2012.groupby?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise! \n",
    "\n",
    "Let's try to get the following:\n",
    "1. Total number of enrolled students per region and gender\n",
    "2. Total number of enrolled students per year level and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region\n",
       "ARMM (Autonomous Region in Muslim Mindanao)     625166\n",
       "CAR (Cordillera Administrative Region)          215480\n",
       "I (Ilocos Region)                               629230\n",
       "II (Cagayan Valley)                             434574\n",
       "III (Central Luzon)                            1315107\n",
       "IV-A (CALABARZON)                              1605041\n",
       "IV-B (MIMAROPA)                                 472905\n",
       "IX (Zamboanga Peninsula)                        580413\n",
       "NCR (National Capital Region)                  1246119\n",
       "V (Bicol Region)                                988787\n",
       "VI (Western Visayas)                           1037886\n",
       "VII (Central Visayas)                          1030357\n",
       "VIII (Eastern Visayas)                          707367\n",
       "X (Northern Mindanao)                           657672\n",
       "XI (Davao Region)                               683089\n",
       "XII (SOCCSKSARGEN)                              627717\n",
       "XIII (Caraga)                                   402579\n",
       "Name: enrollment, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.groupby('region')['enrollment'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>gender</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARMM (Autonomous Region in Muslim Mindanao)</td>\n",
       "      <td>female</td>\n",
       "      <td>325728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARMM (Autonomous Region in Muslim Mindanao)</td>\n",
       "      <td>male</td>\n",
       "      <td>299438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAR (Cordillera Administrative Region)</td>\n",
       "      <td>female</td>\n",
       "      <td>102069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAR (Cordillera Administrative Region)</td>\n",
       "      <td>male</td>\n",
       "      <td>113411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>female</td>\n",
       "      <td>298996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>male</td>\n",
       "      <td>330234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>II (Cagayan Valley)</td>\n",
       "      <td>female</td>\n",
       "      <td>207741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>II (Cagayan Valley)</td>\n",
       "      <td>male</td>\n",
       "      <td>226833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>III (Central Luzon)</td>\n",
       "      <td>female</td>\n",
       "      <td>629770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>III (Central Luzon)</td>\n",
       "      <td>male</td>\n",
       "      <td>685337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IV-A (CALABARZON)</td>\n",
       "      <td>female</td>\n",
       "      <td>768652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IV-A (CALABARZON)</td>\n",
       "      <td>male</td>\n",
       "      <td>836389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IV-B (MIMAROPA)</td>\n",
       "      <td>female</td>\n",
       "      <td>224875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IV-B (MIMAROPA)</td>\n",
       "      <td>male</td>\n",
       "      <td>248030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IX (Zamboanga Peninsula)</td>\n",
       "      <td>female</td>\n",
       "      <td>278387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IX (Zamboanga Peninsula)</td>\n",
       "      <td>male</td>\n",
       "      <td>302026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NCR (National Capital Region)</td>\n",
       "      <td>female</td>\n",
       "      <td>601227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NCR (National Capital Region)</td>\n",
       "      <td>male</td>\n",
       "      <td>644892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>V (Bicol Region)</td>\n",
       "      <td>female</td>\n",
       "      <td>467493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>V (Bicol Region)</td>\n",
       "      <td>male</td>\n",
       "      <td>521294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VI (Western Visayas)</td>\n",
       "      <td>female</td>\n",
       "      <td>491396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VI (Western Visayas)</td>\n",
       "      <td>male</td>\n",
       "      <td>546490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VII (Central Visayas)</td>\n",
       "      <td>female</td>\n",
       "      <td>488937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>VII (Central Visayas)</td>\n",
       "      <td>male</td>\n",
       "      <td>541420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VIII (Eastern Visayas)</td>\n",
       "      <td>female</td>\n",
       "      <td>336485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VIII (Eastern Visayas)</td>\n",
       "      <td>male</td>\n",
       "      <td>370882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>X (Northern Mindanao)</td>\n",
       "      <td>female</td>\n",
       "      <td>314561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>X (Northern Mindanao)</td>\n",
       "      <td>male</td>\n",
       "      <td>343111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XI (Davao Region)</td>\n",
       "      <td>female</td>\n",
       "      <td>326488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XI (Davao Region)</td>\n",
       "      <td>male</td>\n",
       "      <td>356601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>female</td>\n",
       "      <td>304751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>male</td>\n",
       "      <td>322966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XIII (Caraga)</td>\n",
       "      <td>female</td>\n",
       "      <td>192611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XIII (Caraga)</td>\n",
       "      <td>male</td>\n",
       "      <td>209968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         region  gender  enrollment\n",
       "0   ARMM (Autonomous Region in Muslim Mindanao)  female      325728\n",
       "1   ARMM (Autonomous Region in Muslim Mindanao)    male      299438\n",
       "2        CAR (Cordillera Administrative Region)  female      102069\n",
       "3        CAR (Cordillera Administrative Region)    male      113411\n",
       "4                             I (Ilocos Region)  female      298996\n",
       "5                             I (Ilocos Region)    male      330234\n",
       "6                           II (Cagayan Valley)  female      207741\n",
       "7                           II (Cagayan Valley)    male      226833\n",
       "8                           III (Central Luzon)  female      629770\n",
       "9                           III (Central Luzon)    male      685337\n",
       "10                            IV-A (CALABARZON)  female      768652\n",
       "11                            IV-A (CALABARZON)    male      836389\n",
       "12                              IV-B (MIMAROPA)  female      224875\n",
       "13                              IV-B (MIMAROPA)    male      248030\n",
       "14                     IX (Zamboanga Peninsula)  female      278387\n",
       "15                     IX (Zamboanga Peninsula)    male      302026\n",
       "16                NCR (National Capital Region)  female      601227\n",
       "17                NCR (National Capital Region)    male      644892\n",
       "18                             V (Bicol Region)  female      467493\n",
       "19                             V (Bicol Region)    male      521294\n",
       "20                         VI (Western Visayas)  female      491396\n",
       "21                         VI (Western Visayas)    male      546490\n",
       "22                        VII (Central Visayas)  female      488937\n",
       "23                        VII (Central Visayas)    male      541420\n",
       "24                       VIII (Eastern Visayas)  female      336485\n",
       "25                       VIII (Eastern Visayas)    male      370882\n",
       "26                        X (Northern Mindanao)  female      314561\n",
       "27                        X (Northern Mindanao)    male      343111\n",
       "28                            XI (Davao Region)  female      326488\n",
       "29                            XI (Davao Region)    male      356601\n",
       "30                           XII (SOCCSKSARGEN)  female      304751\n",
       "31                           XII (SOCCSKSARGEN)    male      322966\n",
       "32                                XIII (Caraga)  female      192611\n",
       "33                                XIII (Caraga)    male      209968"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012_regions = deped2012.groupby(['region', 'gender'], as_index=False)['enrollment'].sum()\n",
    "deped2012_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>gender</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>female</td>\n",
       "      <td>68125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>male</td>\n",
       "      <td>63189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CARAGA - CARAGA</td>\n",
       "      <td>female</td>\n",
       "      <td>187179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CARAGA - CARAGA</td>\n",
       "      <td>male</td>\n",
       "      <td>205861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>female</td>\n",
       "      <td>290392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>male</td>\n",
       "      <td>322592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Region II - Cagayan Valley</td>\n",
       "      <td>female</td>\n",
       "      <td>207723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Region II - Cagayan Valley</td>\n",
       "      <td>male</td>\n",
       "      <td>227392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Region III - Central Luzon</td>\n",
       "      <td>female</td>\n",
       "      <td>601789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Region III - Central Luzon</td>\n",
       "      <td>male</td>\n",
       "      <td>657231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Region IV-A - CALABARZON</td>\n",
       "      <td>female</td>\n",
       "      <td>750433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Region IV-A - CALABARZON</td>\n",
       "      <td>male</td>\n",
       "      <td>818274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Region IV-B - MIMAROPA</td>\n",
       "      <td>female</td>\n",
       "      <td>210017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Region IV-B - MIMAROPA</td>\n",
       "      <td>male</td>\n",
       "      <td>232212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Region IX - Zamboanga Peninsula</td>\n",
       "      <td>female</td>\n",
       "      <td>260186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Region IX - Zamboanga Peninsula</td>\n",
       "      <td>male</td>\n",
       "      <td>287488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Region V - Bicol Region</td>\n",
       "      <td>female</td>\n",
       "      <td>433489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Region V - Bicol Region</td>\n",
       "      <td>male</td>\n",
       "      <td>484528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Region VI - Western Visayas</td>\n",
       "      <td>female</td>\n",
       "      <td>483669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Region VI - Western Visayas</td>\n",
       "      <td>male</td>\n",
       "      <td>541978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Region VII - Central Visayas</td>\n",
       "      <td>female</td>\n",
       "      <td>478153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Region VII - Central Visayas</td>\n",
       "      <td>male</td>\n",
       "      <td>531120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Region VIII - Eastern Visayas</td>\n",
       "      <td>female</td>\n",
       "      <td>311101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Region VIII - Eastern Visayas</td>\n",
       "      <td>male</td>\n",
       "      <td>345465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Region X - Northern Mindanao</td>\n",
       "      <td>female</td>\n",
       "      <td>311079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Region X - Northern Mindanao</td>\n",
       "      <td>male</td>\n",
       "      <td>341609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Region XI - Davao Region</td>\n",
       "      <td>female</td>\n",
       "      <td>322583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Region XI - Davao Region</td>\n",
       "      <td>male</td>\n",
       "      <td>354880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Region XII - SOCCSKSARGEN</td>\n",
       "      <td>female</td>\n",
       "      <td>295727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Region XII - SOCCSKSARGEN</td>\n",
       "      <td>male</td>\n",
       "      <td>318271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         region  gender  enrollment\n",
       "0   ARMM - Autonomous Region in Muslim Mindanao  female       68125\n",
       "1   ARMM - Autonomous Region in Muslim Mindanao    male       63189\n",
       "2                               CARAGA - CARAGA  female      187179\n",
       "3                               CARAGA - CARAGA    male      205861\n",
       "4                      Region I - Ilocos Region  female      290392\n",
       "5                      Region I - Ilocos Region    male      322592\n",
       "6                    Region II - Cagayan Valley  female      207723\n",
       "7                    Region II - Cagayan Valley    male      227392\n",
       "8                    Region III - Central Luzon  female      601789\n",
       "9                    Region III - Central Luzon    male      657231\n",
       "10                     Region IV-A - CALABARZON  female      750433\n",
       "11                     Region IV-A - CALABARZON    male      818274\n",
       "12                       Region IV-B - MIMAROPA  female      210017\n",
       "13                       Region IV-B - MIMAROPA    male      232212\n",
       "14              Region IX - Zamboanga Peninsula  female      260186\n",
       "15              Region IX - Zamboanga Peninsula    male      287488\n",
       "16                      Region V - Bicol Region  female      433489\n",
       "17                      Region V - Bicol Region    male      484528\n",
       "18                  Region VI - Western Visayas  female      483669\n",
       "19                  Region VI - Western Visayas    male      541978\n",
       "20                 Region VII - Central Visayas  female      478153\n",
       "21                 Region VII - Central Visayas    male      531120\n",
       "22                Region VIII - Eastern Visayas  female      311101\n",
       "23                Region VIII - Eastern Visayas    male      345465\n",
       "24                 Region X - Northern Mindanao  female      311079\n",
       "25                 Region X - Northern Mindanao    male      341609\n",
       "26                     Region XI - Davao Region  female      322583\n",
       "27                     Region XI - Davao Region    male      354880\n",
       "28                    Region XII - SOCCSKSARGEN  female      295727\n",
       "29                    Region XII - SOCCSKSARGEN    male      318271"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015_regions = deped2015.groupby(['region', 'gender'], as_index=False)['enrollment'].sum()\n",
    "deped2015_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grade 1</td>\n",
       "      <td>female</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>1262015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>1500512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grade 2</td>\n",
       "      <td>female</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>1144869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grade 2</td>\n",
       "      <td>male</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>1281188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grade 3</td>\n",
       "      <td>female</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>1052206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grade 3</td>\n",
       "      <td>male</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>1138870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grade 4</td>\n",
       "      <td>female</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>1003971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>grade 4</td>\n",
       "      <td>male</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>1059492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grade 5</td>\n",
       "      <td>female</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>966741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>grade 5</td>\n",
       "      <td>male</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>998887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>grade 6</td>\n",
       "      <td>female</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>930365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>grade 6</td>\n",
       "      <td>male</td>\n",
       "      <td>4759017221</td>\n",
       "      <td>920373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_level  gender   school_id  enrollment\n",
       "0     grade 1  female  4759017221     1262015\n",
       "1     grade 1    male  4759017221     1500512\n",
       "2     grade 2  female  4759017221     1144869\n",
       "3     grade 2    male  4759017221     1281188\n",
       "4     grade 3  female  4759017221     1052206\n",
       "5     grade 3    male  4759017221     1138870\n",
       "6     grade 4  female  4759017221     1003971\n",
       "7     grade 4    male  4759017221     1059492\n",
       "8     grade 5  female  4759017221      966741\n",
       "9     grade 5    male  4759017221      998887\n",
       "10    grade 6  female  4759017221      930365\n",
       "11    grade 6    male  4759017221      920373"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.groupby(['year_level', 'gender'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data\n",
    "\n",
    "Data are sometimes separated into different files or additional data from another source can be associated to another dataset. `pandas` provides means to combine different `DataFrames` together (provided that there are common variables that it can connect them to.\n",
    "\n",
    "#### `pd.merge`\n",
    "`merge()` is very similar to database-style joins. `pandas` allows merging of `DataFrame` and **named** `Series` objects together. A join can be done along columns or indexes.\n",
    "\n",
    "#### `pd.concat`\n",
    "`concat()` on the other hand combines `pandas` objects along a specific axis.\n",
    "\n",
    "#### `df.append`\n",
    "`append()` basically adds the rows of another `DataFrame` or `Series` to the end of the caller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mhow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'inner'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mleft_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mright_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindicator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Merge DataFrame or named Series objects with a database-style join.\n",
       "\n",
       "The join is done on columns or indexes. If joining columns on\n",
       "columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
       "on indexes or indexes on a column or columns, the index will be passed on.\n",
       "When performing a cross merge, no column specifications to merge on are\n",
       "allowed.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "left : DataFrame\n",
       "right : DataFrame or named Series\n",
       "    Object to merge with.\n",
       "how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
       "    Type of merge to be performed.\n",
       "\n",
       "    * left: use only keys from left frame, similar to a SQL left outer join;\n",
       "      preserve key order.\n",
       "    * right: use only keys from right frame, similar to a SQL right outer join;\n",
       "      preserve key order.\n",
       "    * outer: use union of keys from both frames, similar to a SQL full outer\n",
       "      join; sort keys lexicographically.\n",
       "    * inner: use intersection of keys from both frames, similar to a SQL inner\n",
       "      join; preserve the order of the left keys.\n",
       "    * cross: creates the cartesian product from both frames, preserves the order\n",
       "      of the left keys.\n",
       "\n",
       "      .. versionadded:: 1.2.0\n",
       "\n",
       "on : label or list\n",
       "    Column or index level names to join on. These must be found in both\n",
       "    DataFrames. If `on` is None and not merging on indexes then this defaults\n",
       "    to the intersection of the columns in both DataFrames.\n",
       "left_on : label or list, or array-like\n",
       "    Column or index level names to join on in the left DataFrame. Can also\n",
       "    be an array or list of arrays of the length of the left DataFrame.\n",
       "    These arrays are treated as if they are columns.\n",
       "right_on : label or list, or array-like\n",
       "    Column or index level names to join on in the right DataFrame. Can also\n",
       "    be an array or list of arrays of the length of the right DataFrame.\n",
       "    These arrays are treated as if they are columns.\n",
       "left_index : bool, default False\n",
       "    Use the index from the left DataFrame as the join key(s). If it is a\n",
       "    MultiIndex, the number of keys in the other DataFrame (either the index\n",
       "    or a number of columns) must match the number of levels.\n",
       "right_index : bool, default False\n",
       "    Use the index from the right DataFrame as the join key. Same caveats as\n",
       "    left_index.\n",
       "sort : bool, default False\n",
       "    Sort the join keys lexicographically in the result DataFrame. If False,\n",
       "    the order of the join keys depends on the join type (how keyword).\n",
       "suffixes : list-like, default is (\"_x\", \"_y\")\n",
       "    A length-2 sequence where each element is optionally a string\n",
       "    indicating the suffix to add to overlapping column names in\n",
       "    `left` and `right` respectively. Pass a value of `None` instead\n",
       "    of a string to indicate that the column name from `left` or\n",
       "    `right` should be left as-is, with no suffix. At least one of the\n",
       "    values must not be None.\n",
       "copy : bool, default True\n",
       "    If False, avoid copy if possible.\n",
       "indicator : bool or str, default False\n",
       "    If True, adds a column to the output DataFrame called \"_merge\" with\n",
       "    information on the source of each row. The column can be given a different\n",
       "    name by providing a string argument. The column will have a Categorical\n",
       "    type with the value of \"left_only\" for observations whose merge key only\n",
       "    appears in the left DataFrame, \"right_only\" for observations\n",
       "    whose merge key only appears in the right DataFrame, and \"both\"\n",
       "    if the observation's merge key is found in both DataFrames.\n",
       "\n",
       "validate : str, optional\n",
       "    If specified, checks if merge is of specified type.\n",
       "\n",
       "    * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
       "      left and right datasets.\n",
       "    * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
       "      dataset.\n",
       "    * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
       "      dataset.\n",
       "    * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "    A DataFrame of the two merged objects.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "merge_ordered : Merge with optional filling/interpolation.\n",
       "merge_asof : Merge on nearest keys.\n",
       "DataFrame.join : Similar method using indices.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Support for specifying index levels as the `on`, `left_on`, and\n",
       "`right_on` parameters was added in version 0.23.0\n",
       "Support for merging named Series objects was added in version 0.24.0\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
       "...                     'value': [1, 2, 3, 5]})\n",
       ">>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
       "...                     'value': [5, 6, 7, 8]})\n",
       ">>> df1\n",
       "    lkey value\n",
       "0   foo      1\n",
       "1   bar      2\n",
       "2   baz      3\n",
       "3   foo      5\n",
       ">>> df2\n",
       "    rkey value\n",
       "0   foo      5\n",
       "1   bar      6\n",
       "2   baz      7\n",
       "3   foo      8\n",
       "\n",
       "Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
       "the default suffixes, _x and _y, appended.\n",
       "\n",
       ">>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
       "  lkey  value_x rkey  value_y\n",
       "0  foo        1  foo        5\n",
       "1  foo        1  foo        8\n",
       "2  foo        5  foo        5\n",
       "3  foo        5  foo        8\n",
       "4  bar        2  bar        6\n",
       "5  baz        3  baz        7\n",
       "\n",
       "Merge DataFrames df1 and df2 with specified left and right suffixes\n",
       "appended to any overlapping columns.\n",
       "\n",
       ">>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
       "...           suffixes=('_left', '_right'))\n",
       "  lkey  value_left rkey  value_right\n",
       "0  foo           1  foo            5\n",
       "1  foo           1  foo            8\n",
       "2  foo           5  foo            5\n",
       "3  foo           5  foo            8\n",
       "4  bar           2  bar            6\n",
       "5  baz           3  baz            7\n",
       "\n",
       "Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
       "any overlapping columns.\n",
       "\n",
       ">>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
       "Traceback (most recent call last):\n",
       "...\n",
       "ValueError: columns overlap but no suffix specified:\n",
       "    Index(['value'], dtype='object')\n",
       "\n",
       ">>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
       ">>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
       ">>> df1\n",
       "      a  b\n",
       "0   foo  1\n",
       "1   bar  2\n",
       ">>> df2\n",
       "      a  c\n",
       "0   foo  3\n",
       "1   baz  4\n",
       "\n",
       ">>> df1.merge(df2, how='inner', on='a')\n",
       "      a  b  c\n",
       "0   foo  1  3\n",
       "\n",
       ">>> df1.merge(df2, how='left', on='a')\n",
       "      a  b  c\n",
       "0   foo  1  3.0\n",
       "1   bar  2  NaN\n",
       "\n",
       ">>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
       ">>> df2 = pd.DataFrame({'right': [7, 8]})\n",
       ">>> df1\n",
       "    left\n",
       "0   foo\n",
       "1   bar\n",
       ">>> df2\n",
       "    right\n",
       "0   7\n",
       "1   8\n",
       "\n",
       ">>> df1.merge(df2, how='cross')\n",
       "   left  right\n",
       "0   foo      7\n",
       "1   foo      8\n",
       "2   bar      7\n",
       "3   bar      8\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\unisse\\anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobjs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NDFrame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NDFrame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mjoin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverify_integrity\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Series'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Concatenate pandas objects along a particular axis with optional set logic\n",
       "along the other axes.\n",
       "\n",
       "Can also add a layer of hierarchical indexing on the concatenation axis,\n",
       "which may be useful if the labels are the same (or overlapping) on\n",
       "the passed axis number.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "objs : a sequence or mapping of Series or DataFrame objects\n",
       "    If a mapping is passed, the sorted keys will be used as the `keys`\n",
       "    argument, unless it is passed, in which case the values will be\n",
       "    selected (see below). Any None objects will be dropped silently unless\n",
       "    they are all None in which case a ValueError will be raised.\n",
       "axis : {0/'index', 1/'columns'}, default 0\n",
       "    The axis to concatenate along.\n",
       "join : {'inner', 'outer'}, default 'outer'\n",
       "    How to handle indexes on other axis (or axes).\n",
       "ignore_index : bool, default False\n",
       "    If True, do not use the index values along the concatenation axis. The\n",
       "    resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
       "    concatenating objects where the concatenation axis does not have\n",
       "    meaningful indexing information. Note the index values on the other\n",
       "    axes are still respected in the join.\n",
       "keys : sequence, default None\n",
       "    If multiple levels passed, should contain tuples. Construct\n",
       "    hierarchical index using the passed keys as the outermost level.\n",
       "levels : list of sequences, default None\n",
       "    Specific levels (unique values) to use for constructing a\n",
       "    MultiIndex. Otherwise they will be inferred from the keys.\n",
       "names : list, default None\n",
       "    Names for the levels in the resulting hierarchical index.\n",
       "verify_integrity : bool, default False\n",
       "    Check whether the new concatenated axis contains duplicates. This can\n",
       "    be very expensive relative to the actual data concatenation.\n",
       "sort : bool, default False\n",
       "    Sort non-concatenation axis if it is not already aligned when `join`\n",
       "    is 'outer'.\n",
       "    This has no effect when ``join='inner'``, which already preserves\n",
       "    the order of the non-concatenation axis.\n",
       "\n",
       "    .. versionchanged:: 1.0.0\n",
       "\n",
       "       Changed to not sort by default.\n",
       "\n",
       "copy : bool, default True\n",
       "    If False, do not copy data unnecessarily.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "object, type of objs\n",
       "    When concatenating all ``Series`` along the index (axis=0), a\n",
       "    ``Series`` is returned. When ``objs`` contains at least one\n",
       "    ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
       "    the columns (axis=1), a ``DataFrame`` is returned.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Series.append : Concatenate Series.\n",
       "DataFrame.append : Concatenate DataFrames.\n",
       "DataFrame.join : Join DataFrames using indexes.\n",
       "DataFrame.merge : Merge DataFrames by indexes or columns.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The keys, levels, and names arguments are all optional.\n",
       "\n",
       "A walkthrough of how this method fits in with other tools for combining\n",
       "pandas objects can be found `here\n",
       "<https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Combine two ``Series``.\n",
       "\n",
       ">>> s1 = pd.Series(['a', 'b'])\n",
       ">>> s2 = pd.Series(['c', 'd'])\n",
       ">>> pd.concat([s1, s2])\n",
       "0    a\n",
       "1    b\n",
       "0    c\n",
       "1    d\n",
       "dtype: object\n",
       "\n",
       "Clear the existing index and reset it in the result\n",
       "by setting the ``ignore_index`` option to ``True``.\n",
       "\n",
       ">>> pd.concat([s1, s2], ignore_index=True)\n",
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    d\n",
       "dtype: object\n",
       "\n",
       "Add a hierarchical index at the outermost level of\n",
       "the data with the ``keys`` option.\n",
       "\n",
       ">>> pd.concat([s1, s2], keys=['s1', 's2'])\n",
       "s1  0    a\n",
       "    1    b\n",
       "s2  0    c\n",
       "    1    d\n",
       "dtype: object\n",
       "\n",
       "Label the index keys you create with the ``names`` option.\n",
       "\n",
       ">>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
       "...           names=['Series name', 'Row ID'])\n",
       "Series name  Row ID\n",
       "s1           0         a\n",
       "             1         b\n",
       "s2           0         c\n",
       "             1         d\n",
       "dtype: object\n",
       "\n",
       "Combine two ``DataFrame`` objects with identical columns.\n",
       "\n",
       ">>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
       "...                    columns=['letter', 'number'])\n",
       ">>> df1\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       ">>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
       "...                    columns=['letter', 'number'])\n",
       ">>> df2\n",
       "  letter  number\n",
       "0      c       3\n",
       "1      d       4\n",
       ">>> pd.concat([df1, df2])\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       "0      c       3\n",
       "1      d       4\n",
       "\n",
       "Combine ``DataFrame`` objects with overlapping columns\n",
       "and return everything. Columns outside the intersection will\n",
       "be filled with ``NaN`` values.\n",
       "\n",
       ">>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
       "...                    columns=['letter', 'number', 'animal'])\n",
       ">>> df3\n",
       "  letter  number animal\n",
       "0      c       3    cat\n",
       "1      d       4    dog\n",
       ">>> pd.concat([df1, df3], sort=False)\n",
       "  letter  number animal\n",
       "0      a       1    NaN\n",
       "1      b       2    NaN\n",
       "0      c       3    cat\n",
       "1      d       4    dog\n",
       "\n",
       "Combine ``DataFrame`` objects with overlapping columns\n",
       "and return only those that are shared by passing ``inner`` to\n",
       "the ``join`` keyword argument.\n",
       "\n",
       ">>> pd.concat([df1, df3], join=\"inner\")\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       "0      c       3\n",
       "1      d       4\n",
       "\n",
       "Combine ``DataFrame`` objects horizontally along the x axis by\n",
       "passing in ``axis=1``.\n",
       "\n",
       ">>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
       "...                    columns=['animal', 'name'])\n",
       ">>> pd.concat([df1, df4], axis=1)\n",
       "  letter  number  animal    name\n",
       "0      a       1    bird   polly\n",
       "1      b       2  monkey  george\n",
       "\n",
       "Prevent the result from including duplicate index values with the\n",
       "``verify_integrity`` option.\n",
       "\n",
       ">>> df5 = pd.DataFrame([1], index=['a'])\n",
       ">>> df5\n",
       "   0\n",
       "a  1\n",
       ">>> df6 = pd.DataFrame([2], index=['a'])\n",
       ">>> df6\n",
       "   0\n",
       "a  2\n",
       ">>> pd.concat([df5, df6], verify_integrity=True)\n",
       "Traceback (most recent call last):\n",
       "    ...\n",
       "ValueError: Indexes have overlapping values: ['a']\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\unisse\\anaconda3\\envs\\datasci\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deped2012.append?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "The task is to compare the enrollment statistics of the elementary schools between 2012 and 2015. \n",
    "\n",
    "1. Get the total number of enrolled students per school for each year\n",
    "2. Merge the two `DataFrame`s together to show the summarized statistics for the two years for all schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012 = deped2012.groupby('school_id', as_index=False).sum()\n",
    "stats2015 = deped2015.groupby('school_id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  enrollment\n",
       "0     100001          72\n",
       "1     100002         365\n",
       "2     100003         138\n",
       "3     100004          89\n",
       "4     100005          73"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38659, 2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2012.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  enrollment\n",
       "0     100001          72\n",
       "1     100002         407\n",
       "2     100003         152\n",
       "3     100004         107\n",
       "4     100005          67"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33024, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2015.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012['year'] = 2012\n",
    "stats2015['year'] = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>365</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>138</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>89</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>73</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33019</th>\n",
       "      <td>133553</td>\n",
       "      <td>142</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33020</th>\n",
       "      <td>133554</td>\n",
       "      <td>253</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33021</th>\n",
       "      <td>133555</td>\n",
       "      <td>240</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33022</th>\n",
       "      <td>133556</td>\n",
       "      <td>333</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33023</th>\n",
       "      <td>133557</td>\n",
       "      <td>401</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71683 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       school_id  enrollment  year\n",
       "0         100001          72  2012\n",
       "1         100002         365  2012\n",
       "2         100003         138  2012\n",
       "3         100004          89  2012\n",
       "4         100005          73  2012\n",
       "...          ...         ...   ...\n",
       "33019     133553         142  2015\n",
       "33020     133554         253  2015\n",
       "33021     133555         240  2015\n",
       "33022     133556         333  2015\n",
       "33023     133557         401  2015\n",
       "\n",
       "[71683 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_table = pd.concat([stats2012, stats2015])\n",
    "wide_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>365</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>407</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>138</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  enrollment  year\n",
       "0     100001          72  2012\n",
       "0     100001          72  2015\n",
       "1     100002         365  2012\n",
       "1     100002         407  2015\n",
       "2     100003         138  2012"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_table.sort_values(by=['school_id', 'year'], inplace=True)\n",
    "wide_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "1. Are the number of rows for both `DataFrames` the same or different? What's the implication if they're different?\n",
    "2. Note the same column names for the two `DataFrames`. Based on the documentation for `merge()`, there's a parameter for suffixes for overlapping column names. If we want to avoid the \"messy\" suffixes, we can choose to rename columns prior to merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way is to assign an array to the columns object representing the column names for ALL columns.\n",
    "\n",
    "```ipython\n",
    "stats2012.columns = ['school_id', '2012']\n",
    "stats2015.columns = ['school_id', '2015']\n",
    "```\n",
    "\n",
    "But this is not good if you have too many columns... `pandas` has a function `rename()` in which we can pass a \"mappable\" dictionary for the columns. The `inplace` parameter helps in renaming it and assigns the changed `DataFrame` back to the same variable.\n",
    "\n",
    "```ipython\n",
    "stats2012.rename(columns={'enrollment': '2012'}, inplace=True)\n",
    "stats2015.rename(columns={'enrollment': '2015'}, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the code above\n",
    "stats2012.columns = ['school_id', '2012']\n",
    "stats2015.columns = ['school_id', '2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>2012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  2012\n",
       "0     100001    72\n",
       "1     100002   365\n",
       "2     100003   138\n",
       "3     100004    89\n",
       "4     100005    73"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>2012</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>365.0</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>138.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>89.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>73.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38680</th>\n",
       "      <td>133129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38681</th>\n",
       "      <td>133150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38682</th>\n",
       "      <td>133191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38683</th>\n",
       "      <td>133198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38684</th>\n",
       "      <td>133201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38685 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       school_id   2012   2015\n",
       "0         100001   72.0   72.0\n",
       "1         100002  365.0  407.0\n",
       "2         100003  138.0  152.0\n",
       "3         100004   89.0  107.0\n",
       "4         100005   73.0   67.0\n",
       "...          ...    ...    ...\n",
       "38680     133129    NaN    0.0\n",
       "38681     133150    NaN  113.0\n",
       "38682     133191    NaN   28.0\n",
       "38683     133198    NaN   23.0\n",
       "38684     133201    NaN   35.0\n",
       "\n",
       "[38685 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Merge the two dataframes using different \"how\" parameters\n",
    "# how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
    "stats_combined = stats2012.merge(stats2015, on='school_id', how='outer')\n",
    "stats_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_id       0\n",
       "2012           26\n",
       "2015         5661\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "38685 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015  33024\n",
    "# 2012  38659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5635"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "38659 - 33024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38633"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32998 + 5635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
