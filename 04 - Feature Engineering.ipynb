{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On: Feature Engineering\n",
    "\n",
    "This hands-on will cover some techniques in feature engineering in combination with data cleaning and processing.\n",
    "\n",
    "It covers feature extraction from `datetime` objects, feature transformation from existing variables in the dataset, feature generation and some categorical encoding such as count, label and one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - CitiBike Trip Histories\n",
    "\n",
    "CitiBike provides the data of the bike share through this website: https://www.citibikenyc.com/system-data\n",
    "\n",
    "For this exercise, we'll be using their trip history data which may be found [here](https://s3.amazonaws.com/tripdata/index.html). \n",
    "\n",
    "Kindly choose a 2021 month file to download (not the ones with JC as the prefix). You can download data for January or Febuary (20-50MB in file size for slow internet connections) and extract it to your data folder.\n",
    "\n",
    "**CitiBike trip data includes:**\n",
    "\n",
    "* Trip Duration (seconds)\n",
    "* Start Time and Date\n",
    "* Stop Time and Date\n",
    "* Start Station Name\n",
    "* End Station Name\n",
    "* Station ID\n",
    "* Station Lat/Long\n",
    "* Bike ID\n",
    "* User Type (Customer = 24-hour pass or 3-day pass user; Subscriber = Annual Member)\n",
    "* Gender (Zero=unknown; 1=male; 2=female)\n",
    "* Year of Birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSV File and loading it into a pandas dataframe\n",
    "data = pd.read_csv('Dataset/201712-citibike-tripdata.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "\n",
    "These are the types of the dataset. We have a mix of **categorical** (Stations, User Type, Gender), **temporal** (Start Time, Stop Time, Trip Duration) **spatial** and **numerical** data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "From the lecture, we mentioned that we can extract additional information from `datetime` features. Prior to extracting these features, we need to ensure that the `datetime` feature is a `datetime` object in Python so we can easily use the functions available to extract the information.\n",
    "\n",
    "However, sometimes date and time columns are not automatically converted into a `datetime` object, they are loaded as a `str`. We can be convert the column in two ways:\n",
    "\n",
    "1. During `pd.read_csv` using the `parse_dates` argument and passing the column name or the index of the column.\n",
    "2. `pd.to_datetime` method by updating the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the date columns have the datetime data type\n",
    "data['starttime'] = pd.to_datetime(data['starttime'])\n",
    "data['stoptime'] = pd.to_datetime(data['stoptime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime-like properties in `pandas`\n",
    "\n",
    "Datetimelike properties in a `pandas.Series` can be accessed through `Series.dt`\n",
    "\n",
    "See the [`pandas` documentation for datetimelike properties](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#datetimelike-properties) to see all possible values.\n",
    "\n",
    "For this exercise, let's extract the **day of the week** and the **hour of the day** from the starttime. Create a new column for these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the day of week  - start is monday (0)\n",
    "data['dayofweek'] = data['starttime'].dt.dayofweek\n",
    "\n",
    "# Get the day of week (name)\n",
    "data['dayof_week'] = data['starttime'].dt.day_name()\n",
    "\n",
    "#Get the hour of day\n",
    "data['hourofday'] = data['starttime'].dt.hour\n",
    "\n",
    "#Get the year\n",
    "data['year'] = data['starttime'].dt.year\n",
    "\n",
    "#Is weekend or not\n",
    "#List comprehension\n",
    "data['weekend_weekday_lc'] = ['Weekend' if i >= 5 else 'Weekday' for i in data['dayofweek']]\n",
    "\n",
    "\n",
    "#Is weekend or not\n",
    "# Regular for loops\n",
    "weekend_tag = []\n",
    "for each in data['dayofweek']:\n",
    "    if each >= 5:\n",
    "        weekend_tag.append('Weekend - Regular Loop')\n",
    "        \n",
    "    else:\n",
    "        weekend_tag.append('Weekday - Regular Loop')\n",
    "        \n",
    "data['weekend_weekday_rl'] = weekend_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if elements were correctly encoded\n",
    "data[['dayofweek', 'dayof_week','weekend_weekday_lc', 'weekend_weekday_rl']].drop_duplicates().sort_values(by='dayofweek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation\n",
    "\n",
    "Currently, the trip duration is in seconds. Depending on the use case or analysis, using seconds might not be easily interpreted by most since we're used to either a trip lasting minutes or hours. \n",
    "\n",
    "Let's transform the tripduration in seconds to minutes and see how long the trip actually took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration_min'] = data['tripduration']/60\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want to get hour?\n",
    "data['duration_hour'] = (data['tripduration']/60) / 60\n",
    "\n",
    "# another solution\n",
    "data['duration_hour_2'] = data['duration_min']/60\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "\n",
    "Calculate the age from the birth year.\n",
    "\n",
    "Observe nulls, the min and max of the calculated birth year. Notice anything problematic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total rows without birth year info\n",
    "data['birth year'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of nulls with respect to the entire dataset\n",
    "(data['birth year'].isna().sum() / len(data['birth year'])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill value for nulls is 1700\n",
    "data['birth year'] = data['birth year'].fillna(1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = data['starttime'].dt.year - data['birth year']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of age\n",
    "# Look for outliers\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Age Distribution of Passengers', fontsize=20)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(data['age'], alpha = 0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you want to filter trips\n",
    "# Lets say we will only consider trips of clients from 0 - 100\n",
    "\n",
    "data = data[data['age'] <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of age after filtering\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Age Distribution of Passengers', fontsize=20)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(data['age'], alpha = 0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance\n",
    "\n",
    "Another feature we can generate from the data is distance. Although the provided values are in longitude and latitudes and they're measured in degrees, the distance calculated from these points would also be in degrees (and not meters). \n",
    "\n",
    "There's actually a library that specifically handles geospatial data called `geopy` ([Link](https://geopy.readthedocs.io/en/stable/#module-geopy.distance)). For simplicity sake in this tutorial, we use an existing function that calculates the geodesic distance using the Haversine formula given the starting and ending longitude and latitudes: `calculate_distance(lat1, lon1, lat2, lon2)`\n",
    "\n",
    "Credits to [Wayne Dyck](https://gist.github.com/rochacbruno/2883505) for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculates the distance provided a pair of longitudes and latitudes\n",
    "    using the Haversine formula\n",
    "    \n",
    "    Returns the distance in kilometers.\n",
    "    \"\"\"\n",
    "    radius = 6371 # km\n",
    "\n",
    "    dlat = math.radians(lat2-lat1)\n",
    "    dlon = math.radians(lon2-lon1)\n",
    "    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
    "        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['distance_km'] = data.apply(lambda x: calculate_distance(x['start station latitude'], x['start station longitude'],\n",
    "                                        x['end station latitude'], x['end station longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Encoding\n",
    "\n",
    "Using the trips raw can be quite useful, but what if we had a different problem we wanted to solve. For example, we want to use the number of trips per origin-destination pair to plan for the initial placement of bikes per station so we can balance out the supply and demand.\n",
    "\n",
    "We would simply need the number of trips (or bikes used) per origin-destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count of rides per OD\n",
    "od_trips = data.groupby(['start station name', 'end station name'], as_index=False)['bikeid'].count()\n",
    "od_trips.sort_values(by='bikeid', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also make this into an origin-destination matrix - which can be useful for visualization and also comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(od_trips, index='start station name', columns='end station name', values='bikeid').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding and One-Hot Encoding\n",
    "\n",
    "`scikit-learn` provides encoding functions for preprocessing of data before model training. In this example, we'll use the `usertype` and `gender` categories of the Citibike data for illustration on how to use these encoders.\n",
    "\n",
    "For further reading on other preprocessing techiniques scikit learn offers, see this [article](https://scikit-learn.org/stable/modules/preprocessing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data[['bikeid', 'usertype', 'gender']]\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_usertype = LabelEncoder()\n",
    "users['user_encoded'] = le_usertype.fit_transform(users.usertype)\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[['usertype', 'user_encoded']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_ohe = OneHotEncoder()\n",
    "usertype_ohe = OneHotEncoder()\n",
    "X_gender = gender_ohe.fit_transform(users.gender.values.reshape(-1,1)).toarray()\n",
    "X_usertype = usertype_ohe.fit_transform(users.usertype.values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_usertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_OH = pd.DataFrame(X_gender, columns = [\"gender_\"+str(int(i)) for i in range(X_gender.shape[1])])\n",
    "users_test = pd.concat([users, users_OH], axis=1)\n",
    "\n",
    "users_OH = pd.DataFrame(X_usertype, columns = [\"usertype_\"+str(int(i)) for i in range(X_usertype.shape[1])])\n",
    "users_test = pd.concat([users_test, users_OH], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding (using only `pandas`!!!)\n",
    "\n",
    "`pandas` also has a nifty feature of turning categorical values into numerical labels. \n",
    "\n",
    "Steps:\n",
    "1. Convert the type of the column into category\n",
    "2. Use `cat.codes` to get the integer label for each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['usertype'] = users['usertype'].astype('category')\n",
    "users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['usertype'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['usertype_code'] = users['usertype'].cat.codes\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding using `pandas`\n",
    "\n",
    "`pandas` also has this function called `get_dummies` where it will provide you the binary flags for each category in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(users, columns=['usertype']).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
