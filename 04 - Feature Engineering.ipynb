{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On: Feature Engineering\n",
    "\n",
    "This hands-on will cover some techniques in feature engineering in combination with data cleaning and processing.\n",
    "\n",
    "It covers feature extraction from `datetime` objects, feature transformation from existing variables in the dataset, feature generation and some categorical encoding such as count, label and one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - CitiBike Trip Histories\n",
    "\n",
    "CitiBike provides the data of the bike share through this website: https://www.citibikenyc.com/system-data\n",
    "\n",
    "For this exercise, we'll be using their trip history data which may be found [here](https://s3.amazonaws.com/tripdata/index.html). \n",
    "\n",
    "Kindly choose a 2021 month file to download (not the ones with JC as the prefix). You can download data for January or Febuary (20-50MB in file size for slow internet connections) and extract it to your data folder.\n",
    "\n",
    "**CitiBike trip data includes:**\n",
    "\n",
    "* Trip Duration (seconds)\n",
    "* Start Time and Date\n",
    "* Stop Time and Date\n",
    "* Start Station Name\n",
    "* End Station Name\n",
    "* Station ID\n",
    "* Station Lat/Long\n",
    "* Bike ID\n",
    "* User Type (Customer = 24-hour pass or 3-day pass user; Subscriber = Annual Member)\n",
    "* Gender (Zero=unknown; 1=male; 2=female)\n",
    "* Year of Birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>2017-12-01 00:00:00</td>\n",
       "      <td>2017-12-01 00:04:17</td>\n",
       "      <td>324</td>\n",
       "      <td>DeKalb Ave &amp; Hudson Ave</td>\n",
       "      <td>40.689888</td>\n",
       "      <td>-73.981013</td>\n",
       "      <td>262</td>\n",
       "      <td>Washington Park</td>\n",
       "      <td>40.691782</td>\n",
       "      <td>-73.973730</td>\n",
       "      <td>18858</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325</td>\n",
       "      <td>2017-12-01 00:00:17</td>\n",
       "      <td>2017-12-01 00:05:43</td>\n",
       "      <td>470</td>\n",
       "      <td>W 20 St &amp; 8 Ave</td>\n",
       "      <td>40.743453</td>\n",
       "      <td>-74.000040</td>\n",
       "      <td>490</td>\n",
       "      <td>8 Ave &amp; W 33 St</td>\n",
       "      <td>40.751551</td>\n",
       "      <td>-73.993934</td>\n",
       "      <td>19306</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>967</td>\n",
       "      <td>2017-12-01 00:00:19</td>\n",
       "      <td>2017-12-01 00:16:26</td>\n",
       "      <td>347</td>\n",
       "      <td>Greenwich St &amp; W Houston St</td>\n",
       "      <td>40.728846</td>\n",
       "      <td>-74.008591</td>\n",
       "      <td>504</td>\n",
       "      <td>1 Ave &amp; E 16 St</td>\n",
       "      <td>40.732219</td>\n",
       "      <td>-73.981656</td>\n",
       "      <td>28250</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>2017-12-01 00:00:20</td>\n",
       "      <td>2017-12-01 00:02:26</td>\n",
       "      <td>3077</td>\n",
       "      <td>Stagg St &amp; Union Ave</td>\n",
       "      <td>40.708771</td>\n",
       "      <td>-73.950953</td>\n",
       "      <td>3454</td>\n",
       "      <td>Leonard St &amp; Maujer St</td>\n",
       "      <td>40.710369</td>\n",
       "      <td>-73.947060</td>\n",
       "      <td>25834</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>451</td>\n",
       "      <td>2017-12-01 00:00:28</td>\n",
       "      <td>2017-12-01 00:08:00</td>\n",
       "      <td>368</td>\n",
       "      <td>Carmine St &amp; 6 Ave</td>\n",
       "      <td>40.730386</td>\n",
       "      <td>-74.002150</td>\n",
       "      <td>326</td>\n",
       "      <td>E 11 St &amp; 1 Ave</td>\n",
       "      <td>40.729538</td>\n",
       "      <td>-73.984267</td>\n",
       "      <td>14769</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration            starttime             stoptime  start station id  \\\n",
       "0           256  2017-12-01 00:00:00  2017-12-01 00:04:17               324   \n",
       "1           325  2017-12-01 00:00:17  2017-12-01 00:05:43               470   \n",
       "2           967  2017-12-01 00:00:19  2017-12-01 00:16:26               347   \n",
       "3           125  2017-12-01 00:00:20  2017-12-01 00:02:26              3077   \n",
       "4           451  2017-12-01 00:00:28  2017-12-01 00:08:00               368   \n",
       "\n",
       "            start station name  start station latitude  \\\n",
       "0      DeKalb Ave & Hudson Ave               40.689888   \n",
       "1              W 20 St & 8 Ave               40.743453   \n",
       "2  Greenwich St & W Houston St               40.728846   \n",
       "3         Stagg St & Union Ave               40.708771   \n",
       "4           Carmine St & 6 Ave               40.730386   \n",
       "\n",
       "   start station longitude  end station id        end station name  \\\n",
       "0               -73.981013             262         Washington Park   \n",
       "1               -74.000040             490         8 Ave & W 33 St   \n",
       "2               -74.008591             504         1 Ave & E 16 St   \n",
       "3               -73.950953            3454  Leonard St & Maujer St   \n",
       "4               -74.002150             326         E 11 St & 1 Ave   \n",
       "\n",
       "   end station latitude  end station longitude  bikeid    usertype  \\\n",
       "0             40.691782             -73.973730   18858  Subscriber   \n",
       "1             40.751551             -73.993934   19306  Subscriber   \n",
       "2             40.732219             -73.981656   28250  Subscriber   \n",
       "3             40.710369             -73.947060   25834  Subscriber   \n",
       "4             40.729538             -73.984267   14769  Subscriber   \n",
       "\n",
       "   birth year  gender  \n",
       "0      1981.0       1  \n",
       "1      1992.0       1  \n",
       "2      1992.0       1  \n",
       "3      1988.0       1  \n",
       "4      1986.0       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the CSV File and loading it into a pandas dataframe\n",
    "data = pd.read_csv('data/201712-citibike-tripdata.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripduration                 int64\n",
       "starttime                   object\n",
       "stoptime                    object\n",
       "start station id             int64\n",
       "start station name          object\n",
       "start station latitude     float64\n",
       "start station longitude    float64\n",
       "end station id               int64\n",
       "end station name            object\n",
       "end station latitude       float64\n",
       "end station longitude      float64\n",
       "bikeid                       int64\n",
       "usertype                    object\n",
       "birth year                 float64\n",
       "gender                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes\n",
    "# if you have dates in your data, it's important to convert them to a datetime object so that we can\n",
    "# do functions on them to extract information from them.\n",
    "\n",
    "# NOTE: Always check the datatypes first!\n",
    "# we need to compare the data that we can see in the data.head() to their datatype so that we can see\n",
    "# if the expected data type is the same as the data type of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripduration                 int64\n",
       "starttime                   object\n",
       "stoptime                    object\n",
       "start station id             int64\n",
       "start station name          object\n",
       "start station latitude     float64\n",
       "start station longitude    float64\n",
       "end station id               int64\n",
       "end station name            object\n",
       "end station latitude       float64\n",
       "end station longitude      float64\n",
       "bikeid                       int64\n",
       "usertype                    object\n",
       "birth year                 float64\n",
       "gender                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "\n",
    "These are the types of the dataset. We have a mix of **categorical** (Stations, User Type, Gender), **temporal** (Start Time, Stop Time, Trip Duration) **spatial** and **numerical** data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "From the lecture, we mentioned that we can extract additional information from `datetime` features. Prior to extracting these features, we need to ensure that the `datetime` feature is a `datetime` object in Python so we can easily use the functions available to extract the information.\n",
    "\n",
    "However, sometimes date and time columns are not automatically converted into a `datetime` object, they are loaded as a `str`. We can be convert the column in two ways:\n",
    "\n",
    "1. During `pd.read_csv` using the `parse_dates` argument and passing the column name or the index of the column.\n",
    "2. `pd.to_datetime` method by updating the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the date columns have the datetime data type\n",
    "data['starttime'] = pd.to_datetime(data['starttime'])\n",
    "data['stoptime'] = pd.to_datetime(data['stoptime'])\n",
    "\n",
    "# -> re-assign the entire column after transforming it to a datetime object\n",
    "# -> NOTE: If the datetime format is not the same for all of the obeservation, then it might not be\n",
    "# able to detect the parts of the date and time (i.e., where is the year, month, etc.). This is why\n",
    "# the format should be the same for all. \n",
    "# -> You can also specify the string format of the datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime?\n",
    "\n",
    "# -> If it meets a string that does not meet the format/default, then it will raise specific errors\n",
    "# for specific situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripduration                        int64\n",
       "starttime                  datetime64[ns]\n",
       "stoptime                   datetime64[ns]\n",
       "start station id                    int64\n",
       "start station name                 object\n",
       "start station latitude            float64\n",
       "start station longitude           float64\n",
       "end station id                      int64\n",
       "end station name                   object\n",
       "end station latitude              float64\n",
       "end station longitude             float64\n",
       "bikeid                              int64\n",
       "usertype                           object\n",
       "birth year                        float64\n",
       "gender                              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime-like properties in `pandas`\n",
    "\n",
    "Datetimelike properties in a `pandas.Series` can be accessed through `Series.dt`\n",
    "\n",
    "See the [`pandas` documentation for datetimelike properties](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#datetimelike-properties) to see all possible values.\n",
    "\n",
    "For this exercise, let's extract the **day of the week** and the **hour of the day** from the starttime. Create a new column for these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the day of week  - start is monday (0)\n",
    "data['dayofweek'] = data['starttime'].dt.dayofweek\n",
    "\n",
    "# Get the day of week (name)\n",
    "data['dayof_week'] = data['starttime'].dt.day_name()\n",
    "\n",
    "#Get the hour of day\n",
    "data['hourofday'] = data['starttime'].dt.hour\n",
    "\n",
    "#Get the year\n",
    "data['year'] = data['starttime'].dt.year\n",
    "\n",
    "#Is weekend or not\n",
    "#List comprehension\n",
    "data['weekend_weekday_lc'] = ['Weekend' if i >= 5 else 'Weekday' for i in data['dayofweek']]\n",
    "\n",
    "\n",
    "#Is weekend or not\n",
    "# Regular for loops\n",
    "weekend_tag = []\n",
    "for each in data['dayofweek']:\n",
    "    if each >= 5:\n",
    "        weekend_tag.append('Weekend - Regular Loop')\n",
    "        \n",
    "    else:\n",
    "        weekend_tag.append('Weekday - Regular Loop')\n",
    "        \n",
    "data['weekend_weekday_rl'] = weekend_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if elements were correctly encoded\n",
    "data[['dayofweek', 'dayof_week','weekend_weekday_lc', 'weekend_weekday_rl']].drop_duplicates().sort_values(by='dayofweek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation\n",
    "\n",
    "Currently, the trip duration is in seconds. Depending on the use case or analysis, using seconds might not be easily interpreted by most since we're used to either a trip lasting minutes or hours. \n",
    "\n",
    "Let's transform the tripduration in seconds to minutes and see how long the trip actually took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration_min'] = data['tripduration']/60\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want to get hour?\n",
    "data['duration_hour'] = (data['tripduration']/60) / 60\n",
    "\n",
    "# another solution\n",
    "data['duration_hour_2'] = data['duration_min']/60\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "\n",
    "Calculate the age from the birth year.\n",
    "\n",
    "Observe nulls, the min and max of the calculated birth year. Notice anything problematic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total rows without birth year info\n",
    "data['birth year'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of nulls with respect to the entire dataset\n",
    "(data['birth year'].isna().sum() / len(data['birth year'])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill value for nulls is 1700\n",
    "data['birth year'] = data['birth year'].fillna(1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = data['starttime'].dt.year - data['birth year']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of age\n",
    "# Look for outliers\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Age Distribution of Passengers', fontsize=20)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(data['age'], alpha = 0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you want to filter trips\n",
    "# Lets say we will only consider trips of clients from 0 - 100\n",
    "\n",
    "data = data[data['age'] <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of age after filtering\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title('Age Distribution of Passengers', fontsize=20)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(data['age'], alpha = 0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance\n",
    "\n",
    "Another feature we can generate from the data is distance. Although the provided values are in longitude and latitudes and they're measured in degrees, the distance calculated from these points would also be in degrees (and not meters). \n",
    "\n",
    "There's actually a library that specifically handles geospatial data called `geopy` ([Link](https://geopy.readthedocs.io/en/stable/#module-geopy.distance)). For simplicity sake in this tutorial, we use an existing function that calculates the geodesic distance using the Haversine formula given the starting and ending longitude and latitudes: `calculate_distance(lat1, lon1, lat2, lon2)`\n",
    "\n",
    "Credits to [Wayne Dyck](https://gist.github.com/rochacbruno/2883505) for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculates the distance provided a pair of longitudes and latitudes\n",
    "    using the Haversine formula\n",
    "    \n",
    "    Returns the distance in kilometers.\n",
    "    \"\"\"\n",
    "    radius = 6371 # km\n",
    "\n",
    "    dlat = math.radians(lat2-lat1)\n",
    "    dlon = math.radians(lon2-lon1)\n",
    "    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
    "        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['distance_km'] = data.apply(lambda x: calculate_distance(x['start station latitude'], x['start station longitude'],\n",
    "                                        x['end station latitude'], x['end station longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Encoding\n",
    "\n",
    "Using the trips raw can be quite useful, but what if we had a different problem we wanted to solve. For example, we want to use the number of trips per origin-destination pair to plan for the initial placement of bikes per station so we can balance out the supply and demand.\n",
    "\n",
    "We would simply need the number of trips (or bikes used) per origin-destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count of rides per OD\n",
    "od_trips = data.groupby(['start station name', 'end station name'], as_index=False)['bikeid'].count()\n",
    "od_trips.sort_values(by='bikeid', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also make this into an origin-destination matrix - which can be useful for visualization and also comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(od_trips, index='start station name', columns='end station name', values='bikeid').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding and One-Hot Encoding\n",
    "\n",
    "`scikit-learn` provides encoding functions for preprocessing of data before model training. In this example, we'll use the `usertype` and `gender` categories of the Citibike data for illustration on how to use these encoders.\n",
    "\n",
    "For further reading on other preprocessing techiniques scikit learn offers, see this [article](https://scikit-learn.org/stable/modules/preprocessing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data[['bikeid', 'usertype', 'gender']]\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_usertype = LabelEncoder()\n",
    "users['user_encoded'] = le_usertype.fit_transform(users.usertype)\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[['usertype', 'user_encoded']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_ohe = OneHotEncoder()\n",
    "usertype_ohe = OneHotEncoder()\n",
    "X_gender = gender_ohe.fit_transform(users.gender.values.reshape(-1,1)).toarray()\n",
    "X_usertype = usertype_ohe.fit_transform(users.usertype.values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_usertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_OH = pd.DataFrame(X_gender, columns = [\"gender_\"+str(int(i)) for i in range(X_gender.shape[1])])\n",
    "users_test = pd.concat([users, users_OH], axis=1)\n",
    "\n",
    "users_OH = pd.DataFrame(X_usertype, columns = [\"usertype_\"+str(int(i)) for i in range(X_usertype.shape[1])])\n",
    "users_test = pd.concat([users_test, users_OH], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding (using only `pandas`!!!)\n",
    "\n",
    "`pandas` also has a nifty feature of turning categorical values into numerical labels. \n",
    "\n",
    "Steps:\n",
    "1. Convert the type of the column into category\n",
    "2. Use `cat.codes` to get the integer label for each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['usertype'] = users['usertype'].astype('category')\n",
    "users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['usertype'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['usertype_code'] = users['usertype'].cat.codes\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding using `pandas`\n",
    "\n",
    "`pandas` also has this function called `get_dummies` where it will provide you the binary flags for each category in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(users, columns=['usertype']).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
